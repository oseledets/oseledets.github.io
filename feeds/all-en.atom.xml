<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Scientific Computing group</title><link href="/" rel="alternate"></link><link href="/feeds/all-en.atom.xml" rel="self"></link><id>/</id><updated>2015-11-04T00:00:00+03:00</updated><entry><title>New paper in J. Chem. Phys</title><link href="/news/new-paper-in-j-chem-phys/" rel="alternate"></link><updated>2015-11-04T00:00:00+03:00</updated><author><name>Ivan Oseledets</name></author><id>tag:,2015-11-04:news/new-paper-in-j-chem-phys/</id><summary type="html">&lt;p&gt;Our paper on [multidimensional potential energy surfaces approximation] using a combination of active subspace methods and tensor train&amp;nbsp;decomposition &lt;/p&gt;
&lt;p&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Fitting high-dimensional potential energy surface using active subspace and tensor train (&lt;span class="caps"&gt;AS&lt;/span&gt;+&lt;span class="caps"&gt;TT&lt;/span&gt;) method&amp;#8221;
by V. Baranov and &lt;a href="../../people/oseledets"&gt;I. Oseledets&lt;/a&gt;
is now 
&lt;a href="http://dx.doi.org/10.1063/1.4935017"&gt;published in Journal of Chemical&amp;nbsp;Physics&lt;/a&gt;&lt;/p&gt;</summary><category term="paper"></category></entry><entry><title>Anton Sukhinov leaves the group</title><link href="/news/anton-sukhinov-leaves-the-group/" rel="alternate"></link><updated>2015-09-07T00:00:00+03:00</updated><author><name>Ivan Oseledets</name></author><id>tag:,2015-09-07:news/anton-sukhinov-leaves-the-group/</id><summary type="html">&lt;p&gt;Our research scientist &lt;a href="../../people/sukhinov"&gt;Anton Sukhinov&lt;/a&gt; has finished working at Scientific Computing group. We thank
Anton for his valuable contributions to the research agenda and for his work with the industrial partners (Huawei, Intel) and 
wish him good luck in his future&amp;nbsp;career.&lt;/p&gt;</summary><category term="people"></category></entry><entry><title>MMMA-2015</title><link href="/news/mmma-2015/" rel="alternate"></link><updated>2015-08-29T00:00:00+03:00</updated><author><name>Ivan Oseledets</name></author><id>tag:,2015-08-29:news/mmma-2015/</id><summary type="html">&lt;p&gt;We have succesfully hosted at Skoltech &lt;a href="http://matrix.inm.ras.ru/mmma-2015"&gt;4-th international conference on Matrices in Mathematics and Applications&lt;/a&gt;, &lt;span class="caps"&gt;MMMA&lt;/span&gt;-2015.
More than 100 talks from 6 countries and 10 universities. This is the first conference at our new building of such, and 
we had many interesting talks and discussions. The talks and videos will be soon posted on the &lt;a href="http://matrix.inm.ras.ru/mmma-2015"&gt;conference website&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img width="600" class="center" src="/images/mmma-2015.jpg"&gt;&lt;/p&gt;</summary><category term="conference"></category></entry><entry><title>Path integrals &amp; low-rank for unbounded domains</title><link href="/news/path-integrals-low-rank-for-unbounded-domains/" rel="alternate"></link><updated>2015-05-24T00:00:00+03:00</updated><author><name>Ivan Oseledets</name></author><id>tag:,2015-05-24:news/path-integrals-low-rank-for-unbounded-domains/</id><summary type="html">&lt;p&gt;Path integrals play a dominant role in description of a wide range of problems in physics and mathematics.
They are a universal and powerful tool 
for condensed matter and  high-energy physics,
theory of stochastic processes 
and parabolic differential equations,
financial modelling, quantum chemistry and many&amp;nbsp;others. &lt;/p&gt;
&lt;p&gt;The solution of the one-dimensional reaction-diffusion equation
with initial distribution &lt;span class="math"&gt;\(f(x): \mathbb{R} \to \mathbb{R}^{+}\)&lt;/span&gt;
and a constant diffusion coefficient~&lt;span class="math"&gt;\(\sigma\)&lt;/span&gt;
&lt;/p&gt;
&lt;div class="math"&gt;\begin{equation}
 \frac{\partial}{\partial t} u(x,t)
 = \sigma \frac{\partial^2}{\partial x^2} u(x,t) - V(x,t) u(x,t), \quad  u(x,0)=f(x)
\right.
\qquad t \in [0, T],
\quad x \in \mathbb{R}.
\end{equation}&lt;/div&gt;
&lt;p&gt;
can be expressed by the&amp;nbsp;Feynman-Kac 
&lt;/p&gt;
&lt;div class="math"&gt;\begin{equation}
u_{f}(x,T)=\int_{\mathcal C\{x,0; T \}}  f(\xi(T))
 e^{-\int_{0}^{T}\! V(\xi(\tau),T-\tau) d\tau }
\mathcal{D}_{\xi},
\end{equation}&lt;/div&gt;
&lt;p&gt;
where the integration is done over a set of all
continuous paths &lt;span class="math"&gt;\(\xi(T): [0,T]\to \mathbb{R}\)&lt;/span&gt;
from the Banach space &lt;span class="math"&gt;\(\Xi([0,T], \mathbb{R})\)&lt;/span&gt;
starting at &lt;span class="math"&gt;\(\xi(0)=x\)&lt;/span&gt; and stopping at arbitrary endpoints at time~&lt;span class="math"&gt;\(T\)&lt;/span&gt;.
The integration is then replaced by an &lt;span class="math"&gt;\(n\)&lt;/span&gt;-dimensional&amp;nbsp;integral.&lt;/p&gt;
&lt;p&gt;We present an efficient method for the computation of such path integrals with &lt;span class="math"&gt;\(\mathcal{O}(n + M \log M)\)&lt;/span&gt; complexity 
where &lt;span class="math"&gt;\(n\)&lt;/span&gt; is the number of time steps and &lt;span class="math"&gt;\(M\)&lt;/span&gt; is the size of the spatial mesh, where the solution is sought. 
Using such approach, we can treat problems with non-periodic / non-decaying potentials. For the details, see the&amp;nbsp;preprint.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1504.06149"&gt;Preprint on&amp;nbsp;arXiv&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }
    
    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript'; 
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="paper"></category></entry><entry><title>Cross-conv paper published!</title><link href="/news/cross-conv-paper-published/" rel="alternate"></link><updated>2015-04-03T00:00:00+03:00</updated><author><name>Ivan Oseledets</name></author><id>tag:,2015-04-03:news/cross-conv-paper-published/</id><summary type="html">&lt;p&gt;Our &lt;a href="../convolution-via-cross-approximation"&gt;cross-convolution paper&lt;/a&gt; 
&amp;#8220;Fast Multidimensional Convolution in Low-Rank Tensor Formats via Cross Approximation&amp;#8221;
by &lt;a href="../../people/rakhuba"&gt;M. Rakhuba&lt;/a&gt;, &lt;a href="../../people/oseledets"&gt;I. Oseledets&lt;/a&gt;
is now 
&lt;a href="http://epubs.siam.org/doi/abs/10.1137/140958529"&gt;published in &lt;span class="caps"&gt;SIAM&lt;/span&gt; Journal on Scientific&amp;nbsp;Computing&lt;/a&gt;&lt;/p&gt;</summary><category term="paper"></category></entry><entry><title>Similarity for heterogeneous networks</title><link href="/news/similarity-for-heterogeneous-networks/" rel="alternate"></link><updated>2015-02-24T00:00:00+03:00</updated><author><name>Ivan Oseledets</name></author><id>tag:,2015-02-24:news/similarity-for-heterogeneous-networks/</id><summary type="html">&lt;p&gt;We propose a generalization of SimRank similarity measure for heterogeneous information networks.
Each node is associated with a set of objects and there are different possible relations. This is 
encoded into the &lt;strong&gt;adjacency tensor&lt;/strong&gt;, and the TensorSimRank equation is given&amp;nbsp;as&lt;/p&gt;
&lt;div class="math"&gt;$$s_{\alpha \beta} = \sum_{\gamma} w_{\alpha \beta \gamma} r_{\alpha \beta \gamma} s_{\alpha \beta} r_{\beta \alpha \gamma}, 
\quad s_{\alpha \alpha} = 1.$$&lt;/div&gt;
&lt;p&gt;
This equation generalizes the &lt;a href="http://en.wikipedia.org/wiki/SimRank"&gt;classical SimRank similarity measure&lt;/a&gt;.
The simple iteration combined with low-rank approximation of &lt;span class="math"&gt;\(S\)&lt;/span&gt; was proposed as a computational algorithm.&lt;br /&gt;
The model was tested both on synthetic datasets and a real &lt;a href="http://www2.informatik.uni-freiburg.de/~cziegler/BX/"&gt;Book-Crossing Dataset&lt;/a&gt;.
The final network has the structure (Book, Author, Year, Publisher), and an example of a &amp;#8220;closest book&amp;#8221; request to the 
Psychic Sisters
is given in the Table&amp;nbsp;below.&lt;/p&gt;
&lt;div class="newstable"&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Psychic Sisters (Sweet Valley Twins and Friends, No 70)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;The Love Potion (Sweet Valley Twins and Friends, No 72)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;The Curse of the Ruby Necklace (Sweet Valley Twins and Friends Super, No 5)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;She&amp;#8217;s Not What She Seems (Sweet Valley High No. 92)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Are We in Love? (Sweet Valley High, No 94)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Don&amp;#8217;t Go Home With John (Sweet Valley High No. 90)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;In Love With a Prince (Sweet Valley High, No 91)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1502.06818"&gt;Preprint on&amp;nbsp;arXiv&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }
    
    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript'; 
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="paper"></category></entry><entry><title>Time integration of tensor trains published!</title><link href="/news/time-integration-of-tensor-trains-published/" rel="alternate"></link><updated>2015-02-04T00:00:00+03:00</updated><author><name>Ivan Oseledets</name></author><id>tag:,2015-02-04:news/time-integration-of-tensor-trains-published/</id><summary type="html">&lt;p&gt;Our &lt;a href="../time-integration-of-tensor-trains"&gt;paper on time integration of tensor trains&lt;/a&gt; 
&amp;#8220;Time integration of tensor trains&amp;#8221;
by C. Lubich,  &lt;a href="../../people/oseledets"&gt;I. Oseledets&lt;/a&gt;, B. Vandereycken
is now &lt;a href="http://epubs.siam.org/doi/abs/10.1137/140976546"&gt;published in &lt;span class="caps"&gt;SIAM&lt;/span&gt; Journal on Numerical&amp;nbsp;Analysis&lt;/a&gt;&lt;/p&gt;</summary><category term="paper"></category></entry><entry><title>Maximum-volume principle for rectangular matrices</title><link href="/news/maximum-volume-principle-for-rectangular-matrices/" rel="alternate"></link><updated>2015-02-03T00:00:00+03:00</updated><author><name>Ivan Oseledets</name></author><id>tag:,2015-02-03:news/maximum-volume-principle-for-rectangular-matrices/</id><summary type="html">&lt;p&gt;A definition of p-volume of rectangular matrices is given. We generalize the results for square maximum-volume submatrices to the case rectangular maximal-volume submatrices and provide estimates for the growth of the coefficients. Three promising applications of such submatrices are presented: recommender systems, finding maximal elements in low-rank matrices and preconditioning of overdetermined linear&amp;nbsp;systems.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1502.07838"&gt;Preprint on&amp;nbsp;arXiv&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="paper"></category></entry><entry><title>Alexander Mikhalev defends his PhD</title><link href="/news/alexander-mikhalev-defends-his-phd/" rel="alternate"></link><updated>2014-12-30T00:00:00+03:00</updated><author><name>Ivan Oseledets</name></author><id>tag:,2014-12-30:news/alexander-mikhalev-defends-his-phd/</id><summary type="html">&lt;p&gt;Congratulations to Alexander Mikhalev for his successful PhD defense in &lt;span class="caps"&gt;INM&lt;/span&gt; &lt;span class="caps"&gt;RAS&lt;/span&gt;!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.inm.ras.ru/avtoreferat/%D0%9C%D0%B8%D1%85%D0%B0%D0%BB%D0%B5%D0%B2_dissertation.pdf"&gt;Dissertation (in&amp;nbsp;Russian)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary></entry><entry><title>Convolutional neural networks and tensors</title><link href="/news/convolutional-neural-networks-and-tensors/" rel="alternate"></link><updated>2014-12-19T00:00:00+03:00</updated><author><name>Ivan Oseledets</name></author><id>tag:,2014-12-19:news/convolutional-neural-networks-and-tensors/</id><summary type="html">&lt;p&gt;Deep learning is a huge topic today; speeding up the computation with convolutional 
neural network is crucial for fast classification. In &lt;a href="http://arxiv.org/abs/1412.6553"&gt;this work&lt;/a&gt;
we show how fine-tuned canonical polyadic (&lt;span class="caps"&gt;CP&lt;/span&gt;) decomposition can be used to speedup &lt;span class="caps"&gt;CNN&lt;/span&gt; by a factor 
of&amp;nbsp;8-10.  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1412.6553"&gt;Preprint on&amp;nbsp;arXiv&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="paper"></category></entry><entry><title>This is a new page</title><link href="/news/this-is-a-new-page/" rel="alternate"></link><updated>2014-12-02T00:00:00+03:00</updated><author><name>Admin</name></author><id>tag:,2014-12-02:news/this-is-a-new-page/</id><summary type="html">&lt;p&gt;The website is finally&amp;nbsp;online!&lt;/p&gt;
</summary></entry><entry><title>Alternating low-rank method for the Lyapunov equation</title><link href="/news/alternating-low-rank-method-for-the-lyapunov-equation/" rel="alternate"></link><updated>2014-10-13T00:00:00+04:00</updated><author><name>Ivan Oseledets</name></author><id>tag:,2014-10-13:news/alternating-low-rank-method-for-the-lyapunov-equation/</id><summary type="html">&lt;p&gt;Time-stepping free method based on the rational Krylov subspaces play an important role in many 
applications. The adaptative selection of the shifts for the construction of the &lt;span class="caps"&gt;RKS&lt;/span&gt; is crucial.
In this paper we propose a new algorithm for the selection of the shifts. It is based 
on the connection between the solution of the Lyapunov&amp;nbsp;equation&lt;/p&gt;
&lt;div class="math"&gt;$$
   AX + XA^{\top} = y_0 y_0^{\top}
$$&lt;/div&gt;
&lt;p&gt;
and the solution of a linear &lt;span class="caps"&gt;ODE&lt;/span&gt;
&lt;/p&gt;
&lt;div class="math"&gt;$$
   \frac{dy}{dt} = Ay, \quad y(0) = y_0.
$$&lt;/div&gt;
&lt;p&gt;
We have compared the efficiency of the new method with &lt;span class="caps"&gt;KPIK&lt;/span&gt; and &lt;span class="caps"&gt;RKSM&lt;/span&gt; methods (implementation
were taken from the &lt;a href="http://www.dm.unibo.it/~simoncin/software.html"&gt;homepage of Valeria Simonchini&lt;/a&gt;.
The &lt;span class="caps"&gt;ALR&lt;/span&gt; method we propose was the most efficient one (and it is&amp;nbsp;parameter-free).&lt;/p&gt;
&lt;p&gt;&lt;img width="600" class="center" src="/images/diffusion.png"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1410.3335"&gt;Preprint on&amp;nbsp;arXiv&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dkolesnikov/alr"&gt;Code on&amp;nbsp;Github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dkolesnikov/alr-paper"&gt;Code &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; data from the paper on&amp;nbsp;Github&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }
    
    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript'; 
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="paper"></category></entry><entry><title>Time evolution and optimization with MPS</title><link href="/news/time-evolution-and-optimization-with-mps/" rel="alternate"></link><updated>2014-08-21T00:00:00+04:00</updated><author><name>Ivan Oseledets</name></author><id>tag:,2014-08-21:news/time-evolution-and-optimization-with-mps/</id><summary type="html">&lt;p&gt;The &lt;a href="http://arxiv.org/abs/1407.2042"&gt;projector-splitting scheme in the &lt;span class="caps"&gt;TT&lt;/span&gt;/&lt;span class="caps"&gt;MPS&lt;/span&gt; format&lt;/a&gt; is a natural way 
to computing dynamics of quantum spin systems Hamiltonians with long-range interaction. We have proposed a unified 
approach that leads to a cheap and efficient computational scheme that can be applied to any Hamiltonian, 
represented in the &lt;span class="caps"&gt;MPO&lt;/span&gt;/&lt;span class="caps"&gt;TT&lt;/span&gt; form.
&lt;img width="600" class="center" src="/images/jutho.png"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1408.5056"&gt;Preprint on&amp;nbsp;arXiv&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="paper"></category></entry><entry><title>Time integration of tensor trains</title><link href="/news/time-integration-of-tensor-trains/" rel="alternate"></link><updated>2014-08-07T00:00:00+04:00</updated><author><name>Ivan Oseledets</name></author><id>tag:,2014-08-07:news/time-integration-of-tensor-trains/</id><summary type="html">&lt;p&gt;Dynamical low-rank approximation is an efficient framework for solving continious and discrete-time 
problems in high-dimensions. Using the Dirac-Frenkel principle applied to the tensor-train format, 
we have propose a robust and efficient time integrator for the resulting system of nonlinear&amp;nbsp;equations.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1407.2042"&gt;Preprint on&amp;nbsp;arXiv&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Algorithm scheme&lt;/th&gt;
&lt;th&gt;Approximate Laplace inversion&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;img width="300" class="center" src="/images/sweep.png"&gt;&lt;/td&gt;
&lt;td&gt;&lt;img width="300" class="center" src="/images/optim.png"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;</summary><category term="paper"></category></entry><entry><title>Multidimensional integrals in ion-atom collisions</title><link href="/news/multidimensional-integrals-in-ion-atom-collisions/" rel="alternate"></link><updated>2014-03-19T00:00:00+04:00</updated><author><name>Ivan Oseledets</name></author><id>tag:,2014-03-19:news/multidimensional-integrals-in-ion-atom-collisions/</id><summary type="html">&lt;p&gt;Simulation in physics is full of multidimensional integrals. In the paper &lt;a href="http://arxiv.org/abs/1403.4068"&gt;&lt;span class="caps"&gt;M. S.&lt;/span&gt; Litsarev and &lt;span class="caps"&gt;I. V.&lt;/span&gt; Oseledets. Low rank approximations for the &lt;span class="caps"&gt;DEPOSIT&lt;/span&gt; computer code. arXiv preprint 1403.4068, 2014&lt;/a&gt; we consider the
&lt;a href="http://www.sciencedirect.com/science/article/pii/S0010465512003153"&gt;&lt;span class="caps"&gt;DEPOSIT&lt;/span&gt; code&lt;/a&gt; that is suited 
for the computation of ion-atomic collisons. The main computational bottleneck is the computation 
of a three-dimensional integral. We exploit its structure by computing low-rank separated representation
using cross approximation for a two-dimensional function, and exponential sums approach for the Slater density 
function. 
Implementation of this technique decreases the total computational
time by a &lt;strong&gt;factor of 1000&lt;/strong&gt;. What is more important, the general concept can be applied to more complicated models
(like ion-molecule&amp;nbsp;collision).&lt;/p&gt;
&lt;p&gt;$&amp;nbsp;\&lt;/p&gt;
&lt;div class="math"&gt;\begin{array}{cccccc}
\\hline
\\hline
System &amp;amp;  \\gamma\mbox{-Shell} &amp;amp;  N_w  &amp;amp;  T_s  ( \\times10^{-3}  sec) &amp;amp;  T_{D}  (sec) &amp;amp;  T_{D}/T_s   \\\\
\\hline
 Au^{26+}+ O  &amp;amp;  4df^{17}  &amp;amp;  74  &amp;amp;  7.94  &amp;amp;  3.89  &amp;amp;  490   \\\\
 &amp;amp;  4sp^{8}  &amp;amp;  69  &amp;amp;  4.92  &amp;amp;  3.83  &amp;amp;  778   \\\\
 &amp;amp;  3d^{10}  &amp;amp;  73  &amp;amp;  3.59  &amp;amp;  3.88  &amp;amp;  1080   \\\\
 &amp;amp;  3sp^{8}  &amp;amp;  72  &amp;amp;  3.81  &amp;amp;  3.82  &amp;amp;  1003   \\\\ 
 &amp;amp;  2sp^{8}  &amp;amp;  107  &amp;amp;  2.42  &amp;amp;  3.86  &amp;amp;  1592   \\\\
 &amp;amp;  1sp^{2}  &amp;amp;  209  &amp;amp;  1.24  &amp;amp;  3.88  &amp;amp;  3120   \\\\  
\\hline
 U^{28+}+ Xe  &amp;amp;  5sp^{4}  &amp;amp;  62  &amp;amp;  10.1  &amp;amp;  3.94  &amp;amp;  390  \\\\
 &amp;amp;  4df^{24}  &amp;amp;  70  &amp;amp;  6.05  &amp;amp;  3.90  &amp;amp;  644  \\\\
 &amp;amp;  4sp^{8}  &amp;amp;  67  &amp;amp;  5.00  &amp;amp;  3.94  &amp;amp;  788  \\\\
 &amp;amp;  3d^{10}  &amp;amp;  71  &amp;amp;  3.88  &amp;amp;  3.92  &amp;amp;  1011  \\\\
 &amp;amp;  3sp^{8}  &amp;amp;  70  &amp;amp;  3.52  &amp;amp;  3.90  &amp;amp;  1106  \\\\
 &amp;amp;  2sp^{8}  &amp;amp;  105  &amp;amp;  1.99  &amp;amp;  3.87  &amp;amp;  1945  \\\\
 &amp;amp;  1sp^{2}  &amp;amp;  207  &amp;amp;  1.04  &amp;amp;  3.88  &amp;amp;  3723  \\\\
\\hline
\\hline
\\end{array}&lt;/div&gt;
&lt;p&gt;
$&lt;/p&gt;
&lt;p&gt;Time for the old code (&lt;span class="math"&gt;\(T_D)\)&lt;/span&gt; versus the time for the new code (&lt;span class="math"&gt;\(T_s\)&lt;/span&gt;).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1403.4068"&gt;Preprint on&amp;nbsp;arXiv&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }
    
    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript'; 
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="paper"></category></entry><entry><title>Preconditioners for hierarchical matrices</title><link href="/news/preconditioners-for-hierarchical-matrices/" rel="alternate"></link><updated>2014-03-12T00:00:00+04:00</updated><author><name>Ivan Oseledets</name></author><id>tag:,2014-03-12:news/preconditioners-for-hierarchical-matrices/</id><summary type="html">&lt;p&gt;We continue to develop our &lt;a href="https://bitbucket.org/muxas/h2tools"&gt;h2tools&lt;/a&gt; package with the new functionality.
The solution of linear systems with hierarchical matrices plays a crucial role in many applications. 
We use the sparse extended form of the H2-matrices to reduce the initial linear system to a block-structured
linear system and then use this block structure to construct different preconditioners. The most efficient
preconditioner is the preconditioner based on the 
so-called &lt;a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3465730/"&gt;&amp;#8220;reverse-Schur complement&amp;#8221;&lt;/a&gt; method: we solve
the initial system using the availability of the fast matrix-by-vector product, and to solve the corretion equation&lt;br /&gt;
we construct the extended system and make several preconditioned iterative steps with&amp;nbsp;it. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1412.1253"&gt;Preprint on&amp;nbsp;arXiv&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="paper"></category></entry><entry><title>Cross approximation: intro</title><link href="/news/cross-approximation-intro/" rel="alternate"></link><updated>2014-02-26T00:00:00+04:00</updated><author><name>Ivan Oseledets</name></author><id>tag:,2014-02-26:news/cross-approximation-intro/</id><summary type="html">&lt;h3 id="skeleton-decomposition"&gt;Skeleton&amp;nbsp;decomposition&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Cross approximation&lt;/em&gt; and &lt;em&gt;skeleton decomposition&lt;/em&gt; are one of the basic concepts in our research. 
It is all about low-rank matrices which appear in many different applications: integral equations, tensor approximations and 
many others.
Cross approximation is simple and elegant,
but it is not widely known as it should be. Suppose that an &lt;span class="math"&gt;\(n \times m\)&lt;/span&gt; matrix &lt;span class="math"&gt;\(A\)&lt;/span&gt; has rank &lt;span class="math"&gt;\(r\)&lt;/span&gt;. Then it can be &lt;em&gt;exactly recovered&lt;/em&gt; 
from &lt;span class="math"&gt;\(r\)&lt;/span&gt; columns and &lt;span class="math"&gt;\(r\)&lt;/span&gt; rows&amp;nbsp;as
&lt;/p&gt;
&lt;div class="math"&gt;$$
    A = C \widehat{A}^{-1} R,
$$&lt;/div&gt;
&lt;p&gt;
where &lt;span class="math"&gt;\(C\)&lt;/span&gt; are &lt;span class="math"&gt;\(r\)&lt;/span&gt; columns of &lt;span class="math"&gt;\(A\)&lt;/span&gt;, &lt;span class="math"&gt;\(R\)&lt;/span&gt; are &lt;span class="math"&gt;\(r\)&lt;/span&gt; rows of &lt;span class="math"&gt;\(A\)&lt;/span&gt; and &lt;span class="math"&gt;\(\widehat{A}\)&lt;/span&gt; is a submatrix on their intersection.
That means, that only &lt;span class="math"&gt;\((n + m) r\)&lt;/span&gt; elements are required. What about the stability of this decomposition?
Suppose &lt;span class="math"&gt;\(A\)&lt;/span&gt; can be approximated with low rank only&amp;nbsp;approximately:
&lt;/p&gt;
&lt;div class="math"&gt;$$
    A = A_r + E,
$$&lt;/div&gt;
&lt;p&gt;
with &lt;span class="math"&gt;\(\Vert E \Vert = \varepsilon\)&lt;/span&gt;.
How to select an good submatrix. A good guide is the &lt;em&gt;maximum volume&lt;/em&gt; : among all &lt;span class="math"&gt;\(r \times r\)&lt;/span&gt; submatrices select the 
one that has largest volume, i.e. the maximum absolute value of the determinant. Then, the corresponding&amp;nbsp;approximation
&lt;/p&gt;
&lt;div class="math"&gt;$$
   \Vert A - A_{maxvol} \Vert_C \leq (r + 1) \sigma_{r + 1},
$$&lt;/div&gt;
&lt;p&gt;
where &lt;span class="math"&gt;\(\sigma_{r + 1}\)&lt;/span&gt; is the &lt;span class="math"&gt;\((r + 1)\)&lt;/span&gt;-th singular value of &lt;span class="math"&gt;\(A\)&lt;/span&gt; and the error is measured in the Chebyshev norm (maximum absolute&amp;nbsp;value).  &lt;/p&gt;
&lt;h3 id="cross-approximation"&gt;Cross&amp;nbsp;approximation&lt;/h3&gt;
&lt;p&gt;A good question is how to compute (quasi)-optimal submatrices. 
One the possibility is the cross approximation algorithm, which is equivalent to the Gaussian elimination. 
The steps of the algorithm are&amp;nbsp;simple:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Find some pivot &lt;span class="math"&gt;\((i',&amp;nbsp;j')\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Subtract a rank-&lt;span class="math"&gt;\(1\)&lt;/span&gt; cross from the matrix: 
   &lt;div class="math"&gt;$$ A_{ij} := A_{ij} - \frac{A_{i j'}A_{i' j}}{A_{i' j'}}. $$&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;Cycle until the norm of &lt;span class="math"&gt;\(A\)&lt;/span&gt; is small&amp;nbsp;enough.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Different pivoting strategies are possible. The full pivoting assumes that &lt;span class="math"&gt;\((i', j')\)&lt;/span&gt; maximizes the absolute value 
of the residue. This involves &lt;span class="math"&gt;\(\mathcal{O}(nm)\)&lt;/span&gt; complexity and is unacceptable. Partial pivoting can be different: from 
the simplest row pivoting scheme to rook schemes and random&amp;nbsp;sampling. &lt;/p&gt;
&lt;h3 id="maximum-volume"&gt;Maximum-volume&lt;/h3&gt;
&lt;p&gt;Maximum-volume principle is the cornerstone of the low-rank approximation algorithms. 
Although it is often claimed that maximum-volume submatrix is hard to compute, 
there are very efficient algorithms for doing that. Maybe the most promiment one is the algorithm
that computes a maximum-volume submatrix in a tall &lt;span class="math"&gt;\(n \times r\)&lt;/span&gt; matrix. 
It is an iterative algorithm: it starts from a non-singular &lt;span class="math"&gt;\(r \times r\)&lt;/span&gt; submatrix and 
then substitutes one row at a step (greedy approach). For this problem, the convergence is very fast. 
There are few tricks to make it really efficient. The efficient implementations of the &lt;strong&gt;maxvol&lt;/strong&gt; algorithm are
available both in the &lt;span class="caps"&gt;MATLAB&lt;/span&gt; and Python version of the &lt;span class="caps"&gt;TT&lt;/span&gt;-Toolbox.&lt;/p&gt;
&lt;p&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[50]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tt&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;tt.maxvol&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;maxvol&lt;/span&gt;
&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;256&lt;/span&gt;
&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot; Hilbert matrix --- classic low-rank example &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;xrange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;xrange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;u&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linalg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;svd&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;semilogy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;&lt;div class="prompt output_prompt"&gt;Out[50]:&lt;/div&gt;


&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;[&amp;lt;matplotlib.lines.Line2D at 0x10cc69b50&amp;gt;]&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;div class="output_area"&gt;&lt;div class="prompt"&gt;&lt;/div&gt;


&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYMAAAEDCAYAAADX1GjKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Computing the maxvol-skeleton&amp;nbsp;approximation&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[51]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
    &lt;span class="n"&gt;u1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;u&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;v1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;
    &lt;span class="n"&gt;v1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;v1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;
    &lt;span class="n"&gt;s1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;er_svd&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linalg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;norm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;u1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;diag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;v1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot; Computing maxvol indices &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;indu&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;maxvol&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;u1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;indv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;maxvol&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;C&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="n"&gt;indv&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;C&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linalg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;solve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;indu&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="c"&gt;# Computing CC^{-1}&lt;/span&gt;
    &lt;span class="n"&gt;R&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;indu&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;
    
    &lt;span class="n"&gt;er_skel&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linalg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;norm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;R&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    
    &lt;span class="nb"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;SVD er:&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;er_svd&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Skeleton er:&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;er_skel&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;&lt;div class="prompt"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;SVD er: 1.05910918542 Skeleton er: 1.62572489102
SVD er: 0.00594784107656 Skeleton er: 0.0181112433106
SVD er: 2.76537410866e-06 Skeleton er: 5.17080332494e-06
SVD er: 5.96043397807e-10 Skeleton er: 1.55873142365e-09
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }
    
    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript'; 
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="tutorial"></category></entry><entry><title>Convolution via cross approximation</title><link href="/news/convolution-via-cross-approximation/" rel="alternate"></link><updated>2014-02-25T00:00:00+04:00</updated><author><name>Ivan Oseledets</name></author><id>tag:,2014-02-25:news/convolution-via-cross-approximation/</id><summary type="html">&lt;p&gt;Multidimensional convolution plays a crucial role in many 
applications. We have proposed a new method for approximate computation of the convolution 
in &lt;em&gt;low-rank tensor formats&lt;/em&gt;
that is based on the
&lt;em&gt;cross approximation&lt;/em&gt; in the frequency domain. 
The method is applicable to any &lt;span class="caps"&gt;SVD&lt;/span&gt;-based tensor format (skeleton, Tucker,  Tensor Train, Hierachical Tucker).
We have computed Newton potentials of different electronic densities, and also presented preliminary 
results for the solution of the Hartree-Fock equation on tensor product grids.
For a practically interesting range of one-dimensional grid sizes &lt;span class="math"&gt;\(n \sim 10^{3}-10^{5}\)&lt;/span&gt; our algorithm is&amp;nbsp;faster.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;He density&lt;/th&gt;
&lt;th&gt;H2 density&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;img width="270" class="center" src="/images/He_density.jpg"&gt;&lt;/td&gt;
&lt;td&gt;&lt;img width="270" class="center" src="/images/H2_density.jpg"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1402.5649"&gt;Preprint on&amp;nbsp;arXiv&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/rakhuba/tucker3d"&gt;MiniTucker Toolbox on&amp;nbsp;Github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://bitbucket.org/rakhuba/crossconv-experiment"&gt;Data from the paper on&amp;nbsp;Bitbucket&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }
    
    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript'; 
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="paper"></category></entry><entry><title>Theses topics</title><link href="/news/theses-topics/" rel="alternate"></link><updated>2014-02-13T00:00:00+04:00</updated><author><name>Ivan Oseledets</name></author><id>tag:,2014-02-13:news/theses-topics/</id><summary type="html">&lt;p&gt;I have put short descriptions of the available student
project online. &lt;a href="/theses/"&gt;Please&amp;nbsp;check&lt;/a&gt;&lt;/p&gt;</summary><category term="Students"></category></entry><entry><title>Happy new year!</title><link href="/news/happy-new-year/" rel="alternate"></link><updated>2013-01-09T00:21:00+04:00</updated><author><name>Admin</name></author><id>tag:,2013-01-09:news/happy-new-year/</id><summary type="html">&lt;p&gt;2013 is now in its full rights, so it is time to go on with research.
With &lt;a class="reference external" href="http://na.uni-tuebingen.de/~lubich/"&gt;Christian Lubich&lt;/a&gt; we have finished a &lt;a class="reference external" href="http://arxiv.org/abs/1301.1058"&gt;paper on a very efficient
time-stepping scheme for the dynamical low-rank approximation&lt;/a&gt; &amp;#8212;-
so-called &lt;span class="caps"&gt;KLS&lt;/span&gt;-scheme, which is remarkably simple but efficient to
compute the dynamics on low-rank manifolds. It presents a full analysis
for the two-dimensional case, with multidimensional case (&lt;span class="caps"&gt;TT&lt;/span&gt;-format) in&amp;nbsp;progress.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Hello&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
</summary><category term="paper"></category></entry><entry><title>One more paper</title><link href="/news/one-more-paper/" rel="alternate"></link><updated>2012-12-22T22:52:00+04:00</updated><author><name>Admin</name></author><id>tag:,2012-12-22:news/one-more-paper/</id><summary type="html">&lt;p&gt;One more old paper on &lt;a class="reference external" href="http://dx.doi.org/10.1007/s00365-012-9175-x"&gt;explicit representations of simple functions in
tensor formats&lt;/a&gt; is published in the Constructive&amp;nbsp;Approximation!&lt;/p&gt;
</summary><category term="paper"></category></entry><entry><title>Solving parabolic systems (with application to Fokker-Planck)</title><link href="/news/solving-parabolic-systems-with-application-to-fokker-planck/" rel="alternate"></link><updated>2012-12-14T09:57:00+04:00</updated><author><name>Admin</name></author><id>tag:,2012-12-14:news/solving-parabolic-systems-with-application-to-fokker-planck/</id><summary type="html">&lt;p&gt;Our paper on the new time-stepping scheme based on the &lt;span class="caps"&gt;QTT&lt;/span&gt;-format &lt;a class="reference external" href="http://dx.doi.org/10.1137/120864210"&gt;has
been published&lt;/a&gt; in &lt;span class="caps"&gt;SISC&lt;/span&gt;!&lt;/p&gt;
</summary><category term="paper"></category></entry><entry><title>News</title><link href="/news/news/" rel="alternate"></link><updated>2012-10-14T13:42:00+04:00</updated><author><name>Admin</name></author><id>tag:,2012-10-14:news/news/</id><summary type="html">&lt;p&gt;Four papers are in&amp;nbsp;progress : on&amp;nbsp;the block eigenvalue solver in&amp;nbsp;the
&lt;span class="caps"&gt;TT&lt;/span&gt;-format, on&amp;nbsp;the dynamical low-rank approximation, on&amp;nbsp;the tensor
structure of&amp;nbsp;the wavelet tensor train matrix and on&amp;nbsp;the fast solution
of&amp;nbsp;the Stokes problem in&amp;nbsp;tensor format. Hope to finish them&amp;nbsp;soon.&lt;/p&gt;
&lt;/p&gt;&lt;p&gt;Also, I&amp;nbsp;put some time to&amp;nbsp;get an&amp;nbsp;implementation of&amp;nbsp;the &lt;span class="caps"&gt;TT&lt;/span&gt;-Toolbox
in&amp;nbsp;Python. &lt;a class="reference external" href="http://github.com/oseledets/ttpy"&gt;The preliminary version (ttpy 0.1) is&amp;nbsp;available on&amp;nbsp;the
github.&lt;/a&gt; Please take a&amp;nbsp;look on&amp;nbsp;it, if&amp;nbsp;you are&amp;nbsp;interested.&lt;/p&gt;
&lt;/p&gt;</summary></entry><entry><title>Publications of our group</title><link href="/news/publications-of-our-group/" rel="alternate"></link><updated>2012-07-17T20:46:00+04:00</updated><author><name>Admin</name></author><id>tag:,2012-07-17:news/publications-of-our-group/</id><summary type="html">&lt;p&gt;We have recently put the publications of our research group at the
Institute of Numerical Mathematics &lt;span class="caps"&gt;RAS&lt;/span&gt; on the web. The list is not yet
full, but is close. &lt;a class="reference external" href="http://pub.inm.ras.ru"&gt;Check&amp;nbsp;it!&lt;/a&gt;&lt;/p&gt;
&lt;/p&gt;</summary></entry><entry><title>Fast adaptive interpolation of multidimensional arrays in TT-format</title><link href="/news/fast-adaptive-interpolation-of-multidimensional-arrays-in-tt-format/" rel="alternate"></link><updated>2012-06-15T12:59:00+04:00</updated><author><name>Admin</name></author><id>tag:,2012-06-15:news/fast-adaptive-interpolation-of-multidimensional-arrays-in-tt-format/</id><summary type="html">&lt;p&gt;&lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=29"&gt;This paper&lt;/a&gt; with Dmitry Savostyanov published in&amp;nbsp;the end of&amp;nbsp;2011
in&amp;nbsp;the Proceedings of&amp;nbsp;7th International Workshop on&amp;nbsp;Multidimensional
Systems (nDS), doi: &lt;a class="reference external" href="http://dx.doi.org/10.1109/nDS.2011.6076873"&gt;10.1109/nDS.2011.6076873&lt;/a&gt;&amp;nbsp;is about fast adaptive
methods for the approximation of&amp;nbsp;high-dimensional arrays by&amp;nbsp;cross-type
methods (such methods are quite popular for&amp;nbsp;matrices).&lt;/p&gt;
&lt;div&gt;&lt;p&gt;The method of&amp;nbsp;&lt;span class="caps"&gt;TT&lt;/span&gt;-ranks adaptation is&amp;nbsp;based on&amp;nbsp;the &lt;span class="caps"&gt;DMRG&lt;/span&gt;-scheme, which
is&amp;nbsp;a&amp;nbsp;“universal tool” for &lt;span class="caps"&gt;TT&lt;/span&gt;-methods. A&amp;nbsp;prototype implementation (quite
messy, but working) is&amp;nbsp;available in&amp;nbsp;the &lt;a class="reference external" href="https://github.com/oseledets/TT-Toolbox/blob/master/cross/dmrg_cross.m"&gt;Github repository of&amp;nbsp;the
&lt;span class="caps"&gt;TT&lt;/span&gt;-Toolbox&lt;/a&gt;. To&amp;nbsp;make it&amp;nbsp;work, you should install the &lt;a class="reference external" href="http://github.com/oseledets/TT-Toolbox"&gt;&lt;span class="caps"&gt;TT&lt;/span&gt;-Toolbox&lt;/a&gt;&amp;nbsp;itself.&lt;/p&gt;
&lt;/div&gt;&lt;/p&gt;</summary></entry><entry><title>Dynamical TT-approximation</title><link href="/news/dynamical-tt-approximation/" rel="alternate"></link><updated>2012-04-25T23:17:00+04:00</updated><author><name>Admin</name></author><id>tag:,2012-04-25:news/dynamical-tt-approximation/</id><summary type="html">&lt;div&gt;&lt;/p&gt;&lt;p&gt;Dynamical low-rank approximation is&amp;nbsp;a&amp;nbsp;rather new and important topic,
which was studied by&amp;nbsp;Lubich and Koch for low-rank matrices and low-rank
(in&amp;nbsp;the sense of&amp;nbsp;Tucker format) tensor decomposition. Such kind
of&amp;nbsp;techniques were well known in&amp;nbsp;physics in&amp;nbsp;chemistry, going back
to&amp;nbsp;Dirac-Frenkel principle, and &lt;span class="caps"&gt;MCTDH&lt;/span&gt; method for the computation
of&amp;nbsp;quantum molecular vibrations. It&amp;nbsp;was interesting to&amp;nbsp;extend this
approach to&amp;nbsp;the &lt;span class="caps"&gt;TT&lt;/span&gt;-format.&lt;/p&gt;
&lt;/p&gt;&lt;p&gt;&lt;/div&gt;&lt;/p&gt;&lt;p&gt;We&amp;nbsp;did it&amp;nbsp;in&amp;nbsp;our recent paper&lt;a class="reference external" href="http://www.mis.mpg.de/preprints/2012/preprint2012_24.pdf"&gt;**Efficient time-stepping scheme for
dynamics on&amp;nbsp;&lt;span class="caps"&gt;TT&lt;/span&gt;-manifolds**&lt;/a&gt;, which is&amp;nbsp;published as&amp;nbsp;a&amp;nbsp;preprint in&amp;nbsp;&lt;span class="caps"&gt;MIS&lt;/span&gt;
&lt;span class="caps"&gt;MPI&lt;/span&gt;&amp;nbsp;Leipzig. In&amp;nbsp;fact, we&amp;nbsp;managed to&amp;nbsp;provide an&amp;nbsp;efficient numerical
scheme for the computation of&amp;nbsp;the &lt;span class="caps"&gt;TT&lt;/span&gt;-dynamics. The &lt;span class="caps"&gt;MATLAB&lt;/span&gt; implementation
will be&amp;nbsp;soon included in&amp;nbsp;the development &lt;a class="reference external" href="http://github.com/oseledets/TT-Toolbox"&gt;github repository of&amp;nbsp;the
&lt;span class="caps"&gt;TT&lt;/span&gt;-Toolbox&lt;/a&gt;.&lt;/p&gt;
&lt;/p&gt;</summary></entry><entry><title>TT-Toolbox 2.2.</title><link href="/news/tt-toolbox-22/" rel="alternate"></link><updated>2012-02-08T22:07:00+04:00</updated><author><name>Admin</name></author><id>tag:,2012-02-08:news/tt-toolbox-22/</id><summary type="html">&lt;p&gt;&lt;span class="caps"&gt;TT&lt;/span&gt;-Toolbox (&lt;span class="caps"&gt;TT&lt;/span&gt;=Tensor Train) Version&amp;nbsp;2.2&lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;TT&lt;/span&gt;(Tensor Train) format is an efficient way for&amp;nbsp;low-parametric&lt;/p&gt;
&lt;p&gt;representation of high-dimensional tensors. The &lt;span class="caps"&gt;TT&lt;/span&gt;-Toolbox&lt;/p&gt;
&lt;p&gt;is a &lt;span class="caps"&gt;MATLAB&lt;/span&gt; implementation of basic operations&amp;nbsp;with&lt;/p&gt;
&lt;p&gt;tensors in &lt;span class="caps"&gt;TT&lt;/span&gt;-format. It&amp;nbsp;includes:&lt;/p&gt;
&lt;p&gt;* tt_tensor and tt_matrix classes for storing vectors and&amp;nbsp;operators&lt;/p&gt;
&lt;p&gt;* Basic linear algebra subroutines (addition, matrix-by-vector&amp;nbsp;product,&lt;/p&gt;
&lt;p&gt;elementwise multiplication and many others) using standard &lt;span class="caps"&gt;MATLAB&lt;/span&gt;&amp;nbsp;syntax,&lt;/p&gt;
&lt;p&gt;linear complexity in the dimension, reshape&amp;nbsp;function&lt;/p&gt;
&lt;p&gt;* Fast rounding procedure with a prescribed&amp;nbsp;accuracy&lt;/p&gt;
&lt;p&gt;* Advanced approximation and solution&amp;nbsp;techniques:&lt;/p&gt;
&lt;/p&gt;&lt;p&gt;* Approximate solution of linear systems and eigenvalue&amp;nbsp;problems&lt;/p&gt;
&lt;p&gt;* Cross methods to approximate &amp;#8220;black-box&amp;#8221;&amp;nbsp;tensors&lt;/p&gt;
&lt;p&gt;* Wavelet tensor train&amp;nbsp;decomposition&lt;/p&gt;
&lt;/p&gt;&lt;p&gt;* Construction of basic operators and functions (Laplace operator,
function of a &lt;span class="caps"&gt;TT&lt;/span&gt;-tensor)&lt;/p&gt;
&lt;p&gt;* Computation of maximal and minimal elements of a&amp;nbsp;tensor&lt;/p&gt;
&lt;p&gt;* and several&amp;nbsp;others&lt;/p&gt;
&lt;/p&gt;&lt;p&gt;New in Version&amp;nbsp;2.2&lt;/p&gt;
&lt;p&gt;* Better&amp;nbsp;documentation&lt;/p&gt;
&lt;p&gt;* Mixed &lt;span class="caps"&gt;QTT&lt;/span&gt;-Tucker format (qtt_tucker&amp;nbsp;class)&lt;/p&gt;
&lt;p&gt;* reshape function for a &lt;span class="caps"&gt;TT&lt;/span&gt;-tensor/&lt;span class="caps"&gt;TT&lt;/span&gt;-matrix&lt;/p&gt;
&lt;p&gt;* dmrg_cross method for black-box tensor&amp;nbsp;approximation&lt;/p&gt;
&lt;p&gt;* Convolution in &lt;span class="caps"&gt;QTT&lt;/span&gt;-format&lt;/p&gt;
&lt;/p&gt;&lt;p&gt;[drain file 9 url&amp;nbsp;You can get it here: &lt;strong&gt;&lt;span class="caps"&gt;TT&lt;/span&gt;-Toolbox 2.2.&amp;nbsp;]&lt;/strong&gt;&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;If you are interested in getting the current &amp;#8220;development&amp;#8221; version of
the Toolbox, take a look at the github repository
&lt;a class="reference external" href="http://github.com/oseledets/TT-Toolbox"&gt;http://github.com/oseledets/&lt;span class="caps"&gt;TT&lt;/span&gt;-Toolbox/&lt;/a&gt;&lt;/p&gt;
</summary></entry><entry><title>Google My citations</title><link href="/news/google-my-citations/" rel="alternate"></link><updated>2011-12-04T21:10:00+04:00</updated><author><name>Admin</name></author><id>tag:,2011-12-04:news/google-my-citations/</id><summary type="html">&lt;p&gt;Google mycitations service looks great. &lt;a class="reference external" href="http://scholar.google.com/citations?user=5kMqBQEAAAAJ&amp;amp;hl=en"&gt;Here is&amp;nbsp;mine&lt;/a&gt;&lt;/p&gt;
</summary></entry><entry><title>Twitter</title><link href="/news/twitter/" rel="alternate"></link><updated>2011-11-26T16:43:00+04:00</updated><author><name>Admin</name></author><id>tag:,2011-11-26:news/twitter/</id><summary type="html">&lt;p&gt;I decided to by on a twitter also (now posts only in Russian, but who
knows :)&amp;nbsp;)&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://twitter.com/oseledetsivan"&gt;oseledetsivan&lt;/a&gt;&lt;/p&gt;
</summary></entry><entry><title>Tensor-Train decomposition paper finally published!</title><link href="/news/tensor-train-decomposition-paper-finally-published/" rel="alternate"></link><updated>2011-09-26T11:33:00+04:00</updated><author><name>Admin</name></author><id>tag:,2011-09-26:news/tensor-train-decomposition-paper-finally-published/</id><summary type="html">&lt;p&gt;Finally, after more than 2&amp;nbsp;years of&amp;nbsp;reviewing process, the basic paper
on&amp;nbsp;the &lt;span class="caps"&gt;TT&lt;/span&gt;-format is&amp;nbsp;published in&amp;nbsp;&lt;span class="caps"&gt;SISC&lt;/span&gt;!&lt;/p&gt;
&lt;p&gt;You can get the journal version &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=28"&gt;here&lt;/a&gt; or&amp;nbsp;directly at&amp;nbsp;the &lt;a class="reference external" href="http://dx.doi.org/10.1137/090752286"&gt;&lt;span class="caps"&gt;SIAM&lt;/span&gt;&amp;nbsp;website&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The first text was based on&amp;nbsp;the paper “Compact matrix form of&amp;nbsp;the
d-dimensional tensor decomposition”. However, it&amp;nbsp;has improved
(I&amp;nbsp;believe) a&amp;nbsp;lot, and can be&amp;nbsp;considered as&amp;nbsp;as&amp;nbsp;separate&amp;nbsp;paper.&lt;/p&gt;
&lt;p&gt;Also, this paper is&amp;nbsp;the first one, where my&amp;nbsp;1-year old daugther Nastya
has written a&amp;nbsp;small part: look at&amp;nbsp;the Algorithm&amp;nbsp;2, step 2&amp;nbsp;at the end.
These slashes were typed by&amp;nbsp;her, but&amp;nbsp;I only noticed it&amp;nbsp;after publishing&amp;nbsp;:)&lt;/p&gt;
</summary></entry><entry><title>Solution of linear systems in the TT-format</title><link href="/news/solution-of-linear-systems-in-the-tt-format/" rel="alternate"></link><updated>2011-05-05T22:13:00+04:00</updated><author><name>Admin</name></author><id>tag:,2011-05-05:news/solution-of-linear-systems-in-the-tt-format/</id><summary type="html">&lt;p&gt;The new paper, &lt;span class="caps"&gt;S.V.&lt;/span&gt; Dolgov, &lt;span class="caps"&gt;I.V.&lt;/span&gt; Oseledets, &lt;a class="reference external" href="http://www.mis.mpg.de/preprints/2011/preprint2011_19.pdf"&gt;Solution of&amp;nbsp;linear systems
and matrix inversion in&amp;nbsp;the &lt;span class="caps"&gt;TT&lt;/span&gt;-format&lt;/a&gt; describes a&amp;nbsp;&lt;span class="caps"&gt;DMRG&lt;/span&gt;-type method for
the solution of&amp;nbsp;linear systems with both the matrix and the tensor
in&amp;nbsp;the &lt;span class="caps"&gt;TT&lt;/span&gt;-format. The method is&amp;nbsp;able to&amp;nbsp;solve certain structured linear
systems of&amp;nbsp;order 2^d, where d&amp;nbsp;can be&amp;nbsp;of&amp;nbsp;order several hundreds, and
&lt;span class="caps"&gt;TT&lt;/span&gt;-ranks can be&amp;nbsp;of&amp;nbsp;order tensor or&amp;nbsp;hundreds. The solver is&amp;nbsp;available
as&amp;nbsp;a&amp;nbsp;part of&amp;nbsp;the &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/?page_id=24"&gt;&lt;span class="caps"&gt;TT&lt;/span&gt;-Toolbox 2.1&lt;/a&gt;. Moreover, some test data of&amp;nbsp;the
article can be&amp;nbsp;downloaded (the new Toolbox is&amp;nbsp;required to&amp;nbsp;be&amp;nbsp;installed).
You can download it&amp;nbsp;from the page &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/?page_id=89"&gt;Benchmarks and data&lt;/a&gt; or&amp;nbsp;[drain file
8&amp;nbsp;url directly download test data as&amp;nbsp;gzipped tar archive] This archive
contains .mat files with A,x,rhs, where&amp;nbsp;A is&amp;nbsp;a&amp;nbsp;&lt;span class="caps"&gt;TT&lt;/span&gt;-matrix, rhs
is&amp;nbsp;a&amp;nbsp;&lt;span class="caps"&gt;TT&lt;/span&gt;-vector (&lt;span class="caps"&gt;TT&lt;/span&gt;-tensor), x&amp;nbsp;is&amp;nbsp;an&amp;nbsp;approximate solution of&amp;nbsp;A*x = rhs.
You can check this directly by&amp;nbsp;computing in&amp;nbsp;&lt;span class="caps"&gt;MATLAB&lt;/span&gt; norm(A*x&amp;nbsp;—
rhs)/norm(rhs) Be&amp;nbsp;aware, that computing full(A) is&amp;nbsp;prohibitive for all
examples, but full(x) or&amp;nbsp;full(rhs) sometimes is&amp;nbsp;not! I&amp;nbsp;plan to&amp;nbsp;add more
benchmarking data to&amp;nbsp;this page, with more &lt;span class="caps"&gt;TT&lt;/span&gt;-matrices and &lt;span class="caps"&gt;TT&lt;/span&gt;-vectors.&lt;/p&gt;
</summary></entry><entry><title>TT-Toolbox 2.1</title><link href="/news/tt-toolbox-21/" rel="alternate"></link><updated>2011-05-04T18:18:00+04:00</updated><author><name>Admin</name></author><id>tag:,2011-05-04:news/tt-toolbox-21/</id><summary type="html">&lt;p&gt;&lt;span class="caps"&gt;TT&lt;/span&gt;-Toolbox 2.1 is released. It contains several bug fixes. My great
thanks to Sergey Dolgov for writing many important routines and to
Vladimir Kazeev for providing his code for the construction of the
&lt;span class="caps"&gt;QTT&lt;/span&gt;-representation of discrete Laplace operator (it can be done for
extremely high dimensions in a&amp;nbsp;second!).&lt;/p&gt;
&lt;/p&gt;&lt;p&gt;&lt;span class="caps"&gt;TT&lt;/span&gt;-Toolbox 2.1 can be downloaded from [drain file 6 url here] or from
&lt;a class="reference external" href="http://spring.inm.ras.ru/osel/?page_id=24"&gt;the&amp;nbsp;page&lt;/a&gt;&lt;/p&gt;
&lt;/p&gt;&lt;p&gt;The [drain file 7 url short introduction] can be also&amp;nbsp;downloaded.&lt;/p&gt;
&lt;/p&gt;&lt;p&gt;All comments and suggestions are welcome. In the next release we plan to
add the conversion procedures from the T. Kolda/B. Bader Tensor Toolbox
(conversion from ktensor and sptensor classes), and also to provide more
benchmarking&amp;nbsp;examples.&lt;/p&gt;
&lt;/p&gt;</summary></entry><entry><title>TT-Toolbox 2.0</title><link href="/news/tt-toolbox-20/" rel="alternate"></link><updated>2011-03-05T14:34:00+03:00</updated><author><name>Admin</name></author><id>tag:,2011-03-05:news/tt-toolbox-20/</id><summary type="html">&lt;p&gt;New version of &lt;span class="caps"&gt;TT&lt;/span&gt;-Toolbox is&amp;nbsp;released.&lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;TT&lt;/span&gt; Toolbox version 2.0 introduces several major innovations compared to
version&amp;nbsp;1.0.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;New classes tt_tensor and tt_matrix, which now represent &lt;span class="caps"&gt;TT&lt;/span&gt;-tensors
and &lt;span class="caps"&gt;TT&lt;/span&gt;-matrices.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Object-oriented approach allowed to overload many standard &lt;span class="caps"&gt;MATLAB&lt;/span&gt;
functions, including addition,&amp;nbsp;subtraction,&lt;/p&gt;
&lt;/p&gt;&lt;p&gt;&lt;p&gt;multiplication by number, scalar product, norm, Kronecker products,
matrix-by-vector product&amp;nbsp;etc&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Complex arithmetics is&amp;nbsp;supported&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Several subroutines to generate basic &lt;span class="caps"&gt;TT&lt;/span&gt;-tensors and &lt;span class="caps"&gt;TT&lt;/span&gt;-matrices:
matrices of all ones, identity&amp;nbsp;matrix,&lt;/p&gt;
&lt;/p&gt;&lt;p&gt;&lt;p&gt;random &lt;span class="caps"&gt;TT&lt;/span&gt;-tensors with fixed core&amp;nbsp;sizes&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Advances operations, like computation of F(&lt;span class="caps"&gt;TT&lt;/span&gt;) using cross method,
matrix-by-vector product using Krylov methods, dmrg solver for linear&amp;nbsp;systems&amp;#8230;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/p&gt;&lt;p&gt;&lt;span class="caps"&gt;TT&lt;/span&gt;-Toolbox 2.0 can be &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/?page_id=24"&gt;downloaded from this page&lt;/a&gt;, or [drain file 4 url&amp;nbsp;directly].&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=27"&gt;Brief introduction to functionality and&amp;nbsp;changes&lt;/a&gt;&lt;/p&gt;
</summary></entry><entry><title>DMRG+QTT</title><link href="/news/dmrgqtt/" rel="alternate"></link><updated>2010-11-19T03:13:00+03:00</updated><author><name>Admin</name></author><id>tag:,2010-11-19:news/dmrgqtt/</id><summary type="html">&lt;p&gt;&lt;span class="caps"&gt;DMRG&lt;/span&gt; (Density Matrix Renormalization Group) is a very efficient
algorithm for computation of low-lying eigenstates of quantum spin
systems. &lt;span class="caps"&gt;QTT&lt;/span&gt; (Quantics Tensor Train) consists in tensorization of
one-dimensional objects (i.e. vectors of values of function on a grid
with 2^d points) into a d-dimensional tensor, and application of Tensor
Train (&lt;span class="caps"&gt;TT&lt;/span&gt;) format to such tensor. What do they have in common? Check our
new paper, &lt;a class="reference external" href="http://www.mis.mpg.de/preprints/2010/preprint2010_69.pdf"&gt;&lt;span class="caps"&gt;DMRG&lt;/span&gt;+&lt;span class="caps"&gt;QTT&lt;/span&gt; approach to high-dimensional quantum molecular&amp;nbsp;dynamics&lt;/a&gt;&lt;/p&gt;
</summary></entry><entry><title>Tensor Train in a nutshell</title><link href="/news/tensor-train-in-a-nutshell/" rel="alternate"></link><updated>2010-11-02T21:12:00+03:00</updated><author><name>Admin</name></author><id>tag:,2010-11-02:news/tensor-train-in-a-nutshell/</id><summary type="html">&lt;p&gt;I have written a &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=26"&gt;one-page article that describes vital operations in
&lt;span class="caps"&gt;TT&lt;/span&gt;-format&lt;/a&gt;. Hope you will find it convincing, that &lt;span class="caps"&gt;TT&lt;/span&gt;-format is indeed
a very elegant representation for&amp;nbsp;tensors.&lt;/p&gt;
</summary></entry><entry><title>Relation of tensors, quantics TT and wavelet tensor trains</title><link href="/news/relation-of-tensors-quantics-tt-and-wavelet-tensor-trains/" rel="alternate"></link><updated>2010-10-03T08:36:00+04:00</updated><author><name>Admin</name></author><id>tag:,2010-10-03:news/relation-of-tensors-quantics-tt-and-wavelet-tensor-trains/</id><summary type="html">&lt;p&gt;In our paper &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=25"&gt;Algebraic wavelet transform via quantics tensor train
decomposition&lt;/a&gt; we show, how quantics tensor train approach, which
consists in tensorization of vectors and matrices, can be interpreted as
&lt;em&gt;algebraic wavelet transform&lt;/em&gt;. Advantages are especially clear for two
dimensional functions. Besides new results, this approach, called &lt;span class="caps"&gt;WTT&lt;/span&gt;
(wavelet tensor trains) describes several open and interesting&amp;nbsp;problems&lt;/p&gt;
&lt;/p&gt;</summary></entry><entry><title>Preprint 2010-04: Explicit tensor-train representation of certain functions</title><link href="/news/preprint-2010-04-explicit-tensor-train-representation-of-certain-functions/" rel="alternate"></link><updated>2010-08-28T09:35:00+04:00</updated><author><name>Admin</name></author><id>tag:,2010-08-28:news/preprint-2010-04-explicit-tensor-train-representation-of-certain-functions/</id><summary type="html">&lt;p&gt;The aim of &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=24"&gt;Preprint 2010-04&lt;/a&gt; is to construct explicit tensor-train
representations for certain function-related tensors and vectors, which
are constructed on the basis of introduced &lt;em&gt;functional tensor train
decomposition.&lt;/em&gt;These results are then used to construct explicit
quantics tensor train decomposition for polynomial and sine&amp;nbsp;functions.&lt;/p&gt;
</summary></entry><entry><title>Krylov methods for tensors</title><link href="/news/krylov-methods-for-tensors/" rel="alternate"></link><updated>2010-04-12T21:48:00+04:00</updated><author><name>Admin</name></author><id>tag:,2010-04-12:news/krylov-methods-for-tensors/</id><summary type="html">&lt;p&gt;Using Wedderburn rank-reduction formulae (for reference what is that,
please read a &lt;a class="reference external" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.66.8644&amp;amp;rep=rep1&amp;amp;type=pdf"&gt;nice paper by Gene Golub and Moody Chu&lt;/a&gt;) , we managed to
create several robust Krylov methods for the approximation of
three-dimensional tensors. It is a preprint &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=23"&gt;2010-1&lt;/a&gt; of Institute of
Numerical Mathematics. A new general interpretation is given for
rank-revealing methods, which use only matrix-by-vector and
tensor-by-vector-by-vector products. This seems to be also a new (and
simple) derivation of the Lanczos&amp;nbsp;algorithm.&lt;/p&gt;
&lt;p&gt;These methods are very crucial for sparse structured tensors (as
pioneered by the work of Elden and Savas), but they become critical for
the approximation of structured tensor operatiions, for example for the
compression of matrix-by-vector product, where both matrix and vector
are in the Tucker format. In the sequel that is under preparation, these
methods will be extended to &lt;span class="caps"&gt;TT&lt;/span&gt; case, and included in future versions of
&lt;span class="caps"&gt;TT&lt;/span&gt;-Toolbox. This will greatly speed up almost all approximate linear
algebra in it (by a factor of 10 at&amp;nbsp;least).&lt;/p&gt;
</summary></entry><entry><title>Tensor trees and tensor trains</title><link href="/news/tensor-trees-and-tensor-trains/" rel="alternate"></link><updated>2009-09-18T19:32:00+04:00</updated><author><name>Admin</name></author><id>tag:,2009-09-18:news/tensor-trees-and-tensor-trains/</id><summary type="html">&lt;p&gt;In a &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=22"&gt;new paper&lt;/a&gt;, we expose connections between tensor networks and
recent recursive representations of high-dimensional tensors described
by binary tensor trees and based on a sequence of skeleton (dyadic)
decompositions for special unfolding matrices for a given
tensor.Â&amp;nbsp;Â&amp;nbsp;Â&amp;nbsp;Â&amp;nbsp; As the main result, we prove that a tensor decomposition
by any binary tensor tree with certain restrictions on the distribution
of spatial and auxiliary indices reduces to one and same for a
particular case of tree. Since the latter tree is of simple
predetermined shape, it becomes not needed at all in the construction of
numerical algorithms. The tree input is replaced with a permutation of
spatial indices (modes). The corresponding decomposition is given by the
so-called tensor trains and known as &lt;span class="caps"&gt;TT&lt;/span&gt;&amp;nbsp;decomposition.&lt;/p&gt;
</summary></entry><entry><title>Black box cross approximation for multidimensional arrays</title><link href="/news/black-box-cross-approximation-for-multidimensional-arrays/" rel="alternate"></link><updated>2009-07-23T14:15:00+04:00</updated><author><name>Admin</name></author><id>tag:,2009-07-23:news/black-box-cross-approximation-for-multidimensional-arrays/</id><summary type="html">&lt;p&gt;In our new paper, &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=21"&gt;&amp;#8220;&lt;span class="caps"&gt;TT&lt;/span&gt; cross approximation for multidimensional
arrays&amp;#8221;&lt;/a&gt; a new formula is presented for the recovery of a
high-dimensional array from a part of its entries, provided that the
array possesses some low-rank structure, namely it has small compression
ranks (for example, a tensor of low canonical rank satisfies this). The
only previous work known to us is the work by Grasedyck, Espig and
Hackbusch, which uses interpolation on &amp;#8220;fiber crosses&amp;#8221;. It is based on
canonical decomposition, requires minimization methods and there is no
guarantee that the method will work even in the exact. Our new
representation solves this problem completely, and it is shown, in
particular, that if the rank of the tensor is r, then it can be exactly
recovered from O(dnr^2) of its entries. This is a natural generalization
of the skeleton decomposition of matrices and it becomes possible due to
the replacement of the canonical format by the &lt;span class="caps"&gt;TT&lt;/span&gt; format, which is
related to a series of matrix decompositions. Â&amp;nbsp; It is also proven that
the &lt;span class="caps"&gt;TT&lt;/span&gt; approximation obtained by a sequence of &lt;span class="caps"&gt;SVD&lt;/span&gt; decompositions can be
worser only up to a factor of \sqrt(d-1)Â&amp;nbsp; then the optimal &lt;span class="caps"&gt;TT&lt;/span&gt;
approximation in the Frobenious&amp;nbsp;norm.&lt;/p&gt;
&lt;p&gt;The simple alternating maxvol algorithm is presented for the computation
of the &lt;span class="caps"&gt;TT&lt;/span&gt;-cross decomposition of a black box tensors, which has
complexity linear in the dimensions, and its effectiveness is
illustratred on several examples inÂ&amp;nbsp; multidimensional integrations,
with dimensions of order hundreds and even thousands. The algorithm is
implemented as part of &lt;span class="caps"&gt;TT&lt;/span&gt; Toolbox and the code will be presented shortly&amp;nbsp;after.&lt;/p&gt;
</summary></entry><entry><title>TT toolbox</title><link href="/news/tt-toolbox/" rel="alternate"></link><updated>2009-05-29T18:36:00+04:00</updated><author><name>Admin</name></author><id>tag:,2009-05-29:news/tt-toolbox/</id><summary type="html">&lt;p&gt;A first version of &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/?page_id=24"&gt;&lt;span class="caps"&gt;TT&lt;/span&gt; toolbox&lt;/a&gt; for &lt;span class="caps"&gt;MATLAB&lt;/span&gt; is released. It seems to
works also under Octave &amp;#8212;- through not fully tested. Any comments,
suggestions and bug reports are welcome at&amp;nbsp;ivan.oseledets(dog)gmail.com&lt;/p&gt;
&lt;p&gt;All basic algorithms are implemented as a set of short &lt;span class="caps"&gt;MATLAB&lt;/span&gt; functions.
You can try to design your own fast algorithm with these routines or
test if there is indeed a hidden &lt;span class="caps"&gt;TT&lt;/span&gt; structure in your
vector/matrix/tensor. Really high-dimensional black box &lt;span class="caps"&gt;TT&lt;/span&gt; approximation
is underway and will be realized soon in the future versions of &lt;span class="caps"&gt;TT&lt;/span&gt;&amp;nbsp;toolbox.&lt;/p&gt;
&lt;p&gt;The efficient Fortran (or C) versions of the &lt;span class="caps"&gt;TT&lt;/span&gt; toolbox are under
development right&amp;nbsp;now.&lt;/p&gt;
</summary></entry><entry><title>Excluded sums and quasiseparable matrices.</title><link href="/news/excluded-sums-and-quasiseparable-matrices/" rel="alternate"></link><updated>2009-05-03T17:45:00+04:00</updated><author><name>Admin</name></author><id>tag:,2009-05-03:news/excluded-sums-and-quasiseparable-matrices/</id><summary type="html">&lt;p&gt;The idea of Edelman et al. (published in 2005 in &lt;span class="caps"&gt;SIAM&lt;/span&gt; News) for fast
evaluation of excluded sums and their relation with the non-recursive
multipole method was largely unnoticed. The authors promised to give a
new implementation of the multipole method based on their (quite
elegant) approach however up to now nothing is known. From my point of
view the problem is that they didn&amp;#8217;t succeed with the efficient
implementation of functional approximations. In our &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=19"&gt;new paper&lt;/a&gt; this
idea is fully investigated in the one-dimensional case. It appears that
it can be done in a simple manner by using successive low-rank skeleton
approximation of a matrices in the lower triangular part and in the
upper triangular part of the matrix and it can be shown that the
obtained method works for an arbitrary quasiseparable matrix (i.e.,
matrix where every submatrix strictly below or over the diagonal has low
rank), and moreover, a new representation for the class of
quasiseparable matrices is obtained. This is a first step in the project
&amp;#8220;Matrix methods for the N-body&amp;nbsp;problems&amp;#8221;.&lt;/p&gt;
&lt;p&gt;The future research will go in two directions. The first one concerns
quasiseparable matrices and effective solvers and eigensolvers using the
new representation and the second is the generalization to two or three&amp;nbsp;dimensions.&lt;/p&gt;
</summary></entry><entry><title>Tensors inside of matrices give logarithmic complexity</title><link href="/news/tensors-inside-of-matrices-give-logarithmic-complexity/" rel="alternate"></link><updated>2009-05-03T17:37:00+04:00</updated><author><name>Admin</name></author><id>tag:,2009-05-03:news/tensors-inside-of-matrices-give-logarithmic-complexity/</id><summary type="html">&lt;p&gt;The recently intoduced &lt;span class="caps"&gt;TT&lt;/span&gt;-format finds a surprising application for the
compression of ordinary &amp;#8220;two&amp;#8221; or &amp;#8220;three&amp;#8221; dimensional matrices, related
to the discretization of operators on tensor grids. For some examples
the complexity is shown to be logarithmic in the matrix order. The new
format (named &lt;span class="caps"&gt;TTM&lt;/span&gt; format) can be used to implement all basic operations
efficiently. The Matlab codes will be posted here soon. The paper itself
is &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=18"&gt;here&lt;/a&gt;&lt;/p&gt;
</summary></entry><entry><title>New tensor decomposition</title><link href="/news/new-tensor-decomposition/" rel="alternate"></link><updated>2009-03-15T03:13:00+03:00</updated><author><name>Admin</name></author><id>tag:,2009-03-15:news/new-tensor-decomposition/</id><summary type="html">&lt;p&gt;A new paper, &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=17"&gt;A compact matrix form of the d-dimensional tensor
decomposition&lt;/a&gt; is added. A new version of the &lt;span class="caps"&gt;TT&lt;/span&gt; (name is now not
coming from &amp;#8220;Tree Tucker&amp;#8221;, but from &amp;#8220;Three dimensional Tensors&amp;#8221; which
are the defining parameters of the format) format is presented, which is
much simpler than the recursive &lt;span class="caps"&gt;TT&lt;/span&gt; format and the subspace format by
Hackbusch and Kuhn (they do not present any numerical experiments). It
presents a nice and clear way to implement basic operations, like
matrix-by-vector product, multidimensional convolution, norms, and what
is the most important, the recompression procedure is based entirely on
the &lt;span class="caps"&gt;SVD&lt;/span&gt; and &lt;span class="caps"&gt;QR&lt;/span&gt; decompositions. Its implementation takes about 150 lines
of Matlab code compared to thousand of lines for the recursive
&lt;span class="caps"&gt;TT&lt;/span&gt;-format, andÂ&amp;nbsp; the results for the computation of the smallest
eigenvalue of a 19-dimensional operator are&amp;nbsp;presented.&lt;/p&gt;
</summary></entry><entry><title>Breaking the curse of dimensionality</title><link href="/news/breaking-the-curse-of-dimensionality/" rel="alternate"></link><updated>2009-01-30T20:29:00+03:00</updated><author><name>Admin</name></author><id>tag:,2009-01-30:news/breaking-the-curse-of-dimensionality/</id><summary type="html">&lt;p&gt;In our new publication, &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=16"&gt;&amp;#8220;Breaking the curse of dimensionality, or how
to use &lt;span class="caps"&gt;SVD&lt;/span&gt; in many dimensions&amp;#8221;&lt;/a&gt; we present a simple recursive
decomposition for multidimensional functions, operators, vectors and
matrices. We prove that in the case when the canonical decomposition
exists our new Tree-Tucker decomposition also exists with the same (and
often fewer) number of parameters. However, unlike the canonical
decomposition, the Tree-Tucker format is stable and robustly computable
by exploiting the &lt;span class="caps"&gt;SVD&lt;/span&gt; decomposition (or any rank-revealing
decomposition). We show how to perform a simple operation
(multidimensional convolution) in such format and provide numerical
experiments for the dimensions up to d=200 on a notebook in several&amp;nbsp;minutes.&lt;/p&gt;
</summary></entry><entry><title>How to find a good submatrix</title><link href="/news/how-to-find-a-good-submatrix/" rel="alternate"></link><updated>2008-10-17T18:22:00+04:00</updated><author><name>Admin</name></author><id>tag:,2008-10-17:news/how-to-find-a-good-submatrix/</id><summary type="html">&lt;p&gt;Check out ourÂ&amp;nbsp; new paper, &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=15"&gt;&amp;#8220;How to find a good submatrix&amp;#8221;&lt;/a&gt; . It
contains the description of an algorithm to find the well-conditioned
submatrix in a given matrix. This algorithm plays a crucial role in our
low-rank approximation methods, both for matrices and tensors. [drain
file 2 url Matlab code is&amp;nbsp;here].&lt;/p&gt;
</summary></entry><entry><title>Working with tensor-structured matrices and vectors</title><link href="/news/working-with-tensor-structured-matrices-and-vectors/" rel="alternate"></link><updated>2008-07-01T00:08:00+04:00</updated><author><name>Admin</name></author><id>tag:,2008-07-01:news/working-with-tensor-structured-matrices-and-vectors/</id><summary type="html">&lt;p&gt;A new publication on tensor-structured matrices, with a tentative title
&lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=13"&gt;&amp;#8220;Linear algebra for tensor problems&amp;#8221;&lt;/a&gt; is added. It is submitted to the
special issue of &lt;a class="reference external" href="http://www.springer.com/springerwiennewyork/mathematics/journal/607"&gt;Computing&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This paper is aboutÂ&amp;nbsp; structured iterations with matrices of low tensor
rank in three dimensions. We show that in three dimensions we can use
&lt;em&gt;Tucker decomposition&lt;/em&gt; instead of the canonical decomposition without
any substantial increase in the computational cost. To achieve this goal
we have to compute quite complex six-fold sum, but it is shown that they
can be computed with calls to &lt;span class="caps"&gt;BLAS&lt;/span&gt;/&lt;span class="caps"&gt;LAPACK&lt;/span&gt;. Therefore Tucker format is
highly recommended for 3-dimensional problems. With a current &lt;span class="caps"&gt;MATLAB&lt;/span&gt;
code (will be posted here soon)Â&amp;nbsp; it is possible to handle dense
matrices (i.e., approximate inversion) on a grid of size 256^3.Â&amp;nbsp; In a
future research by using additional approximation techniques we will be
able to increase this number to at least&amp;nbsp;1024^3.&lt;/p&gt;
</summary></entry><entry><title>One more paper on polynomials</title><link href="/news/one-more-paper-on-polynomials/" rel="alternate"></link><updated>2008-06-18T13:58:00+04:00</updated><author><name>Admin</name></author><id>tag:,2008-06-18:news/one-more-paper-on-polynomials/</id><summary type="html">&lt;p&gt;Added a paper &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=12"&gt;&amp;#8220;Improved n-term Karatsuba formulae in &lt;span class="caps"&gt;GF&lt;/span&gt;(2)&amp;#8221;&lt;/a&gt; that
contains improved (and without proof &amp;#8212;- optimal!) formulae for
multiplication of binary polynomials in &lt;span class="caps"&gt;GF&lt;/span&gt;(2). As noted in the end of
this paper, the goal is not purely theoretic, but also practical &amp;#8212;-
these optimal formulae will be used for the superfast implementation of
the Coppersmith algorithm (as in the work by Thome), where the key step
is the multiplication of binary&amp;nbsp;polynomials.&lt;/p&gt;
</summary></entry><entry><title>Some news</title><link href="/news/some-news/" rel="alternate"></link><updated>2008-05-26T02:04:00+04:00</updated><author><name>Admin</name></author><id>tag:,2008-05-26:news/some-news/</id><summary type="html">&lt;p&gt;A new &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=10"&gt;publication&lt;/a&gt; has been added. To my knowledge, it is the first
paper where nontrivial class of low-tensor rank matrices with inverses
also of a low tensor rank is found. This class is also not very small
and many useful matrices can be reduced to&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;At present, I have several pieces of work to be done: to write down all
results on the optimal multiplication of binary polynomials (generated
code to multiply 128-degree with polynomials with coefficients in &lt;span class="caps"&gt;GF&lt;/span&gt;(2)
optimally), some more &amp;#8220;old&amp;#8221; results need to be written down. What I&amp;#8217;m
interested in really now, is the fast multipole method. After inspecting
several papers by several people (Biros, Ying, Rokhlin and Martinsson,
etc) I&amp;#8217;ve made some conclusions. First, multipole without multipole is
really possible. Second, those authors do a good job, but they do not
want to read the work of others, especially the works by Tyrtyshnikov,
Goreinov and Zamarashkin, the group of Hackbusch. Such reading may
prevent them from reinventing the wheel in some sense. Third, the best
implementation of the fast multipole lies somewhere in between those
several approaches. That is what is interesting to find out &amp;#8212;-
near-to-optimal realization of the fast multipole algorithm. Maybe some
tricks from the tensor approximation will be useful, especially in&amp;nbsp;3D&lt;/p&gt;
</summary></entry><entry><title>Contacts</title><link href="/news/contacts/" rel="alternate"></link><updated>2008-04-03T23:01:00+04:00</updated><author><name>Admin</name></author><id>tag:,2008-04-03:news/contacts/</id><summary type="html">&lt;p&gt;You can always contact&amp;nbsp;me&amp;nbsp;by&amp;nbsp;email:&lt;/p&gt;
&lt;/p&gt;&lt;p&gt;ivan.oseledets &lt;span class="caps"&gt;DOG&lt;/span&gt;&amp;nbsp;gmail.com.&lt;/p&gt;
</summary></entry><entry><title>Publications</title><link href="/news/publications/" rel="alternate"></link><updated>2008-04-03T23:00:00+04:00</updated><author><name>Admin</name></author><id>tag:,2008-04-03:news/publications/</id><summary type="html"></summary></entry><entry><title>Started the creation</title><link href="/news/started-the-creation/" rel="alternate"></link><updated>2008-04-03T22:04:00+04:00</updated><author><name>Admin</name></author><id>tag:,2008-04-03:news/started-the-creation/</id><summary type="html">&lt;p&gt;That is my personal webpage, and I started its creation in April, 2008.
Hope it will be interesting to&amp;nbsp;somebody&lt;/p&gt;
</summary></entry></feed>