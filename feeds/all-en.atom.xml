<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Scientific Computing group</title><link href="/" rel="alternate"></link><link href="/feeds/all-en.atom.xml" rel="self"></link><id>/</id><updated>2016-05-26T00:00:00+03:00</updated><entry><title>A TT-eigenvalue solver that finally works</title><link href="/news/a-tt-eigenvalue-solver-that-finally-works/" rel="alternate"></link><published>2016-05-26T00:00:00+03:00</published><author><name>Ivan Oseledets</name></author><id>tag:,2016-05-26:news/a-tt-eigenvalue-solver-that-finally-works/</id><summary type="html">&lt;p&gt;In a &lt;a href="http://arxiv.org/abs/1605.08422"&gt;recent preprint&lt;/a&gt; by &lt;a href="../../people/rakhuba"&gt;Maxim Rakhuba&lt;/a&gt; and &lt;a href="../../people/oseledets"&gt;Ivan Oseledets&lt;/a&gt; we propose a new algorithm for calculation of vibrational spectra of molecules using tensor train decomposition. Under the assumption that eigenfunctions lie on a low-parametric manifold of low-rank tensors we introduce the concept of manifold preconditioning of well-known iterative methods (inverse iteration and locally optimal block conjugate gradient method). As an application, we accurately compute vibrational spectra (84 states) of acetonitrile molecule on a laptop in one hour using only 180 &lt;span class="caps"&gt;MB&lt;/span&gt; of memory to represent all computed&amp;nbsp;eigenfunctions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1605.08422"&gt;Preprint on&amp;nbsp;arXiv&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://bitbucket.org/rakhuba/ttvibr"&gt;Code on&amp;nbsp;Bitbucket&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="paper"></category></entry><entry><title>Exponential machines and tensor trains</title><link href="/news/exponential-machines-and-tensor-trains/" rel="alternate"></link><published>2016-05-12T00:00:00+03:00</published><author><name>Ivan Oseledets</name></author><id>tag:,2016-05-12:news/exponential-machines-and-tensor-trains/</id><summary type="html">&lt;p&gt;Modeling interactions between features improves the performance of machine learning solutions in many domains (e.g. recommender systems or sentiment analysis). In this paper, we introduce Exponential Machines (ExM), a predictor that models all interactions of every order. The key idea is to represent an exponentially large tensor of parameters in a factorized format called Tensor Train (&lt;span class="caps"&gt;TT&lt;/span&gt;). The Tensor Train format regularizes the model and lets you control the number of underlying parameters. To train the model, we develop a stochastic version of Riemannian optimization, which allows us to fit tensors with &lt;span class="math"&gt;\(2^{30}\)&lt;/span&gt; entries. 
We show that the model achieves state-of-the-art performance on synthetic data with high-order&amp;nbsp;interactions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/bihaqo/exp-machines"&gt;Github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1605.03795"&gt;Preprint on&amp;nbsp;arXiv&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="paper"></category></entry><entry><title>Convergence analysis of a projected fixed-point iteration</title><link href="/news/convergence-analysis-of-a-projected-fixed-point-iteration/" rel="alternate"></link><published>2016-04-06T00:00:00+03:00</published><author><name>Ivan Oseledets</name></author><id>tag:,2016-04-06:news/convergence-analysis-of-a-projected-fixed-point-iteration/</id><summary type="html">&lt;p&gt;In &lt;a href="http://arxiv/abs/1604.02111"&gt;this paper&lt;/a&gt; by &lt;a href="../../people/kolesnikov"&gt;Denis Kolesnikov&lt;/a&gt; and &lt;a href="../../people/oseledets"&gt;Ivan Oseledets&lt;/a&gt; 
we analyse convergence of projected fixed-point iteration on a Riemannian manifold of matrices with fixed rank. As a retraction method we use `projector splitting scheme&amp;#8217;. We prove that the projector splitting scheme converges at least with the same rate as standard fixed-point iteration without rank constraints. We also provide counter-example to the case when conditions of the theorem do not hold. Finally we support our theoretical results with numerical&amp;nbsp;experiments.&lt;/p&gt;
&lt;p&gt;The most interesting finding is the splitting of the error into two components: normal component and tangent component.
The normal component shows staircase convergence which &amp;#8220;feels&amp;#8221; the curvature, but this convergence is much faster, 
thus the total error does not show&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;&lt;img width="600" class="center" src="/images/als_conv.png"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1604.02111"&gt;Preprint on&amp;nbsp;arXiv&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="paper"></category></entry><entry><title>Compress-and-eliminate solver for sparse matrices</title><link href="/news/compress-and-eliminate-solver-for-sparse-matrices/" rel="alternate"></link><published>2016-03-30T00:00:00+03:00</published><author><name>Ivan Oseledets</name></author><id>tag:,2016-03-30:news/compress-and-eliminate-solver-for-sparse-matrices/</id><summary type="html">&lt;p&gt;&lt;a href="http://arxiv/abs/1603.09133"&gt;We propose a new Compress-and-Eliminate Solver for sparse matrices&lt;/a&gt;.
The approach is proposed by &lt;a href="../../people/sushnikova"&gt;Daria Sushnikova&lt;/a&gt; and &lt;a href="../../people/oseledets"&gt;Ivan Oseledets&lt;/a&gt;.
The solver has a very simple algebraic structure, and outperfoms state-of-the art &lt;span class="caps"&gt;CHOLMOD&lt;/span&gt;&amp;nbsp;software.&lt;/p&gt;
&lt;p&gt;&lt;img width="600" class="center" src="/images/ce_solver.png"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1603.09133"&gt;Preprint on&amp;nbsp;arXiv&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="paper"></category></entry><entry><title>New paper in SIMAX</title><link href="/news/new-paper-in-simax/" rel="alternate"></link><published>2015-12-01T00:00:00+03:00</published><author><name>Ivan Oseledets</name></author><id>tag:,2015-12-01:news/new-paper-in-simax/</id><summary type="html">&lt;p&gt;Our paper on a &lt;a href="../../news/alternating-low-rank-method-for-the-lyapunov-equation"&gt;new rational Krylov method for solving large-scale Lyapunov equations&lt;/a&gt; &amp;#8220;From Low-Rank Approximation to a Rational Krylov Subspace Method for the Lyapunov Equation&amp;#8221;
by &lt;a href="../../people/kolesnikov"&gt;D. Kolesnikov&lt;/a&gt; and &lt;a href="../../people/oseledets"&gt;I. Oseledets&lt;/a&gt;
is now 
&lt;a href="http://dx.doi.org/10.1137/140992266"&gt;published in &lt;span class="caps"&gt;SIAM&lt;/span&gt; Journal oon Matrix Analysis and&amp;nbsp;Applications&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1410.3335"&gt;Preprint on&amp;nbsp;arXiv&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dkolesnikov/alr"&gt;Code on&amp;nbsp;Github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dkolesnikov/alr-paper"&gt;Code &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; data from the paper on&amp;nbsp;Github&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="paper"></category></entry><entry><title>New paper in J. Comp. Phys</title><link href="/news/new-paper-in-j-comp-phys/" rel="alternate"></link><published>2015-11-05T00:00:00+03:00</published><author><name>Ivan Oseledets</name></author><id>tag:,2015-11-05:news/new-paper-in-j-comp-phys/</id><summary type="html">&lt;p&gt;Our paper on low-rank computation of huge-dimensional path integrals
&amp;#8220;A low-rank approach to the computation of path integrals&amp;#8221; by &lt;a href="../../people/litsarev"&gt;&lt;span class="caps"&gt;M. S.&lt;/span&gt; Litsarev&lt;/a&gt; and 
&lt;a href="../../people/oseledets"&gt;I. Oseledets&lt;/a&gt; 
&lt;a href="http://dx.doi.org/10.1016/j.jcp.2015.11.009"&gt;published in Journal of Computational&amp;nbsp;Physics&lt;/a&gt;&lt;/p&gt;</summary><category term="paper"></category></entry><entry><title>New paper in J. Chem. Phys</title><link href="/news/new-paper-in-j-chem-phys/" rel="alternate"></link><published>2015-11-04T00:00:00+03:00</published><author><name>Ivan Oseledets</name></author><id>tag:,2015-11-04:news/new-paper-in-j-chem-phys/</id><summary type="html">&lt;p&gt;Our paper on multidimensional potential energy surfaces approximation] using a combination of active subspace methods and tensor train 
decomposition &amp;#8220;Fitting high-dimensional potential energy surface using active subspace and tensor train (&lt;span class="caps"&gt;AS&lt;/span&gt;+&lt;span class="caps"&gt;TT&lt;/span&gt;) method&amp;#8221;
by &lt;a href="../../people/baranov"&gt;V. Baranov&lt;/a&gt; and &lt;a href="../../people/oseledets"&gt;I. Oseledets&lt;/a&gt;
is now 
&lt;a href="http://dx.doi.org/10.1063/1.4935017"&gt;published in Journal of Chemical&amp;nbsp;Physics&lt;/a&gt;&lt;/p&gt;</summary><category term="paper"></category></entry><entry><title>Anton Sukhinov leaves the group</title><link href="/news/anton-sukhinov-leaves-the-group/" rel="alternate"></link><published>2015-09-07T00:00:00+03:00</published><author><name>Ivan Oseledets</name></author><id>tag:,2015-09-07:news/anton-sukhinov-leaves-the-group/</id><summary type="html">&lt;p&gt;Our research scientist &lt;a href="../../people/sukhinov"&gt;Anton Sukhinov&lt;/a&gt; has finished working at Scientific Computing group. We thank
Anton for his valuable contributions to the research agenda and for his work with the industrial partners (Huawei, Intel) and 
wish him good luck in his future&amp;nbsp;career.&lt;/p&gt;</summary><category term="people"></category></entry><entry><title>MMMA-2015</title><link href="/news/mmma-2015/" rel="alternate"></link><published>2015-08-29T00:00:00+03:00</published><author><name>Ivan Oseledets</name></author><id>tag:,2015-08-29:news/mmma-2015/</id><summary type="html">&lt;p&gt;We have succesfully hosted at Skoltech &lt;a href="http://matrix.inm.ras.ru/mmma-2015"&gt;4-th international conference on Matrices in Mathematics and Applications&lt;/a&gt;, &lt;span class="caps"&gt;MMMA&lt;/span&gt;-2015.
More than 100 talks from 6 countries and 10 universities. This is the first conference at our new building of such, and 
we had many interesting talks and discussions. The talks and videos will be soon posted on the &lt;a href="http://matrix.inm.ras.ru/mmma-2015"&gt;conference website&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img width="600" class="center" src="/images/mmma-2015.jpg"&gt;&lt;/p&gt;</summary><category term="conference"></category></entry><entry><title>Path integrals &amp; low-rank for unbounded domains</title><link href="/news/path-integrals-low-rank-for-unbounded-domains/" rel="alternate"></link><published>2015-05-24T00:00:00+03:00</published><author><name>Ivan Oseledets</name></author><id>tag:,2015-05-24:news/path-integrals-low-rank-for-unbounded-domains/</id><summary type="html">&lt;p&gt;Path integrals play a dominant role in description of a wide range of problems in physics and mathematics.
They are a universal and powerful tool 
for condensed matter and  high-energy physics,
theory of stochastic processes 
and parabolic differential equations,
financial modelling, quantum chemistry and many&amp;nbsp;others. &lt;/p&gt;
&lt;p&gt;The solution of the one-dimensional reaction-diffusion equation
with initial distribution &lt;span class="math"&gt;\(f(x): \mathbb{R} \to \mathbb{R}^{+}\)&lt;/span&gt;
and a constant diffusion coefficient~&lt;span class="math"&gt;\(\sigma\)&lt;/span&gt;
&lt;/p&gt;
&lt;div class="math"&gt;\begin{equation}
 \frac{\partial}{\partial t} u(x,t)
 = \sigma \frac{\partial^2}{\partial x^2} u(x,t) - V(x,t) u(x,t), \quad  u(x,0)=f(x)
\right.
\qquad t \in [0, T],
\quad x \in \mathbb{R}.
\end{equation}&lt;/div&gt;
&lt;p&gt;
can be expressed by the&amp;nbsp;Feynman-Kac 
&lt;/p&gt;
&lt;div class="math"&gt;\begin{equation}
u_{f}(x,T)=\int_{\mathcal C\{x,0; T \}}  f(\xi(T))
 e^{-\int_{0}^{T}\! V(\xi(\tau),T-\tau) d\tau }
\mathcal{D}_{\xi},
\end{equation}&lt;/div&gt;
&lt;p&gt;
where the integration is done over a set of all
continuous paths &lt;span class="math"&gt;\(\xi(T): [0,T]\to \mathbb{R}\)&lt;/span&gt;
from the Banach space &lt;span class="math"&gt;\(\Xi([0,T], \mathbb{R})\)&lt;/span&gt;
starting at &lt;span class="math"&gt;\(\xi(0)=x\)&lt;/span&gt; and stopping at arbitrary endpoints at time~&lt;span class="math"&gt;\(T\)&lt;/span&gt;.
The integration is then replaced by an &lt;span class="math"&gt;\(n\)&lt;/span&gt;-dimensional&amp;nbsp;integral.&lt;/p&gt;
&lt;p&gt;We present an efficient method for the computation of such path integrals with &lt;span class="math"&gt;\(\mathcal{O}(n + M \log M)\)&lt;/span&gt; complexity 
where &lt;span class="math"&gt;\(n\)&lt;/span&gt; is the number of time steps and &lt;span class="math"&gt;\(M\)&lt;/span&gt; is the size of the spatial mesh, where the solution is sought. 
Using such approach, we can treat problems with non-periodic / non-decaying potentials. For the details, see the&amp;nbsp;preprint.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1504.06149"&gt;Preprint on&amp;nbsp;arXiv&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="paper"></category></entry><entry><title>Cross-conv paper published!</title><link href="/news/cross-conv-paper-published/" rel="alternate"></link><published>2015-04-03T00:00:00+03:00</published><author><name>Ivan Oseledets</name></author><id>tag:,2015-04-03:news/cross-conv-paper-published/</id><summary type="html">&lt;p&gt;Our &lt;a href="../convolution-via-cross-approximation"&gt;cross-convolution paper&lt;/a&gt; 
&amp;#8220;Fast Multidimensional Convolution in Low-Rank Tensor Formats via Cross Approximation&amp;#8221;
by &lt;a href="../../people/rakhuba"&gt;M. Rakhuba&lt;/a&gt;, &lt;a href="../../people/oseledets"&gt;I. Oseledets&lt;/a&gt;
is now 
&lt;a href="http://epubs.siam.org/doi/abs/10.1137/140958529"&gt;published in &lt;span class="caps"&gt;SIAM&lt;/span&gt; Journal on Scientific&amp;nbsp;Computing&lt;/a&gt;&lt;/p&gt;</summary><category term="paper"></category></entry><entry><title>Similarity for heterogeneous networks</title><link href="/news/similarity-for-heterogeneous-networks/" rel="alternate"></link><published>2015-02-24T00:00:00+03:00</published><author><name>Ivan Oseledets</name></author><id>tag:,2015-02-24:news/similarity-for-heterogeneous-networks/</id><summary type="html">&lt;p&gt;We propose a generalization of SimRank similarity measure for heterogeneous information networks.
Each node is associated with a set of objects and there are different possible relations. This is 
encoded into the &lt;strong&gt;adjacency tensor&lt;/strong&gt;, and the TensorSimRank equation is given&amp;nbsp;as&lt;/p&gt;
&lt;div class="math"&gt;$$s_{\alpha \beta} = \sum_{\gamma} w_{\alpha \beta \gamma} r_{\alpha \beta \gamma} s_{\alpha \beta} r_{\beta \alpha \gamma}, 
\quad s_{\alpha \alpha} = 1.$$&lt;/div&gt;
&lt;p&gt;
This equation generalizes the &lt;a href="http://en.wikipedia.org/wiki/SimRank"&gt;classical SimRank similarity measure&lt;/a&gt;.
The simple iteration combined with low-rank approximation of &lt;span class="math"&gt;\(S\)&lt;/span&gt; was proposed as a computational algorithm.&lt;br /&gt;
The model was tested both on synthetic datasets and a real &lt;a href="http://www2.informatik.uni-freiburg.de/~cziegler/BX/"&gt;Book-Crossing Dataset&lt;/a&gt;.
The final network has the structure (Book, Author, Year, Publisher), and an example of a &amp;#8220;closest book&amp;#8221; request to the 
Psychic Sisters
is given in the Table&amp;nbsp;below.&lt;/p&gt;
&lt;div class="newstable"&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Psychic Sisters (Sweet Valley Twins and Friends, No 70)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;The Love Potion (Sweet Valley Twins and Friends, No 72)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;The Curse of the Ruby Necklace (Sweet Valley Twins and Friends Super, No 5)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;She&amp;#8217;s Not What She Seems (Sweet Valley High No. 92)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Are We in Love? (Sweet Valley High, No 94)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Don&amp;#8217;t Go Home With John (Sweet Valley High No. 90)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;In Love With a Prince (Sweet Valley High, No 91)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1502.06818"&gt;Preprint on&amp;nbsp;arXiv&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="paper"></category></entry><entry><title>Time integration of tensor trains published!</title><link href="/news/time-integration-of-tensor-trains-published/" rel="alternate"></link><published>2015-02-04T00:00:00+03:00</published><author><name>Ivan Oseledets</name></author><id>tag:,2015-02-04:news/time-integration-of-tensor-trains-published/</id><summary type="html">&lt;p&gt;Our &lt;a href="../time-integration-of-tensor-trains"&gt;paper on time integration of tensor trains&lt;/a&gt; 
&amp;#8220;Time integration of tensor trains&amp;#8221;
by C. Lubich,  &lt;a href="../../people/oseledets"&gt;I. Oseledets&lt;/a&gt;, B. Vandereycken
is now &lt;a href="http://epubs.siam.org/doi/abs/10.1137/140976546"&gt;published in &lt;span class="caps"&gt;SIAM&lt;/span&gt; Journal on Numerical&amp;nbsp;Analysis&lt;/a&gt;&lt;/p&gt;</summary><category term="paper"></category></entry><entry><title>Maximum-volume principle for rectangular matrices</title><link href="/news/maximum-volume-principle-for-rectangular-matrices/" rel="alternate"></link><published>2015-02-03T00:00:00+03:00</published><author><name>Ivan Oseledets</name></author><id>tag:,2015-02-03:news/maximum-volume-principle-for-rectangular-matrices/</id><summary type="html">&lt;p&gt;A definition of p-volume of rectangular matrices is given. We generalize the results for square maximum-volume submatrices to the case rectangular maximal-volume submatrices and provide estimates for the growth of the coefficients. Three promising applications of such submatrices are presented: recommender systems, finding maximal elements in low-rank matrices and preconditioning of overdetermined linear&amp;nbsp;systems.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1502.07838"&gt;Preprint on&amp;nbsp;arXiv&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="paper"></category></entry><entry><title>Alexander Mikhalev defends his PhD</title><link href="/news/alexander-mikhalev-defends-his-phd/" rel="alternate"></link><published>2014-12-30T00:00:00+03:00</published><author><name>Ivan Oseledets</name></author><id>tag:,2014-12-30:news/alexander-mikhalev-defends-his-phd/</id><summary type="html">&lt;p&gt;Congratulations to Alexander Mikhalev for his successful PhD defense in &lt;span class="caps"&gt;INM&lt;/span&gt; &lt;span class="caps"&gt;RAS&lt;/span&gt;!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.inm.ras.ru/avtoreferat/%D0%9C%D0%B8%D1%85%D0%B0%D0%BB%D0%B5%D0%B2_dissertation.pdf"&gt;Dissertation (in&amp;nbsp;Russian)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary></entry><entry><title>Convolutional neural networks and tensors</title><link href="/news/convolutional-neural-networks-and-tensors/" rel="alternate"></link><published>2014-12-19T00:00:00+03:00</published><author><name>Ivan Oseledets</name></author><id>tag:,2014-12-19:news/convolutional-neural-networks-and-tensors/</id><summary type="html">&lt;p&gt;Deep learning is a huge topic today; speeding up the computation with convolutional 
neural network is crucial for fast classification. In &lt;a href="http://arxiv.org/abs/1412.6553"&gt;this work&lt;/a&gt;
we show how fine-tuned canonical polyadic (&lt;span class="caps"&gt;CP&lt;/span&gt;) decomposition can be used to speedup &lt;span class="caps"&gt;CNN&lt;/span&gt; by a factor 
of&amp;nbsp;8-10.  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1412.6553"&gt;Preprint on&amp;nbsp;arXiv&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="paper"></category></entry><entry><title>This is a new page</title><link href="/news/this-is-a-new-page/" rel="alternate"></link><published>2014-12-02T00:00:00+03:00</published><author><name>Admin</name></author><id>tag:,2014-12-02:news/this-is-a-new-page/</id><summary type="html">&lt;p&gt;The website is finally&amp;nbsp;online!&lt;/p&gt;
</summary></entry><entry><title>Alternating low-rank method for the Lyapunov equation</title><link href="/news/alternating-low-rank-method-for-the-lyapunov-equation/" rel="alternate"></link><published>2014-10-13T00:00:00+04:00</published><author><name>Ivan Oseledets</name></author><id>tag:,2014-10-13:news/alternating-low-rank-method-for-the-lyapunov-equation/</id><summary type="html">&lt;p&gt;Time-stepping free method based on the rational Krylov subspaces play an important role in many 
applications. The adaptative selection of the shifts for the construction of the &lt;span class="caps"&gt;RKS&lt;/span&gt; is crucial.
In this paper we propose a new algorithm for the selection of the shifts. It is based 
on the connection between the solution of the Lyapunov&amp;nbsp;equation&lt;/p&gt;
&lt;div class="math"&gt;$$
   AX + XA^{\top} = y_0 y_0^{\top}
$$&lt;/div&gt;
&lt;p&gt;
and the solution of a linear &lt;span class="caps"&gt;ODE&lt;/span&gt;
&lt;/p&gt;
&lt;div class="math"&gt;$$
   \frac{dy}{dt} = Ay, \quad y(0) = y_0.
$$&lt;/div&gt;
&lt;p&gt;
We have compared the efficiency of the new method with &lt;span class="caps"&gt;KPIK&lt;/span&gt; and &lt;span class="caps"&gt;RKSM&lt;/span&gt; methods (implementation
were taken from the &lt;a href="http://www.dm.unibo.it/~simoncin/software.html"&gt;homepage of Valeria Simonchini&lt;/a&gt;.
The &lt;span class="caps"&gt;ALR&lt;/span&gt; method we propose was the most efficient one (and it is&amp;nbsp;parameter-free).&lt;/p&gt;
&lt;p&gt;&lt;img width="600" class="center" src="/images/diffusion.png"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1410.3335"&gt;Preprint on&amp;nbsp;arXiv&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dkolesnikov/alr"&gt;Code on&amp;nbsp;Github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dkolesnikov/alr-paper"&gt;Code &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; data from the paper on&amp;nbsp;Github&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="paper"></category></entry><entry><title>Time evolution and optimization with MPS</title><link href="/news/time-evolution-and-optimization-with-mps/" rel="alternate"></link><published>2014-08-21T00:00:00+04:00</published><author><name>Ivan Oseledets</name></author><id>tag:,2014-08-21:news/time-evolution-and-optimization-with-mps/</id><summary type="html">&lt;p&gt;The &lt;a href="http://arxiv.org/abs/1407.2042"&gt;projector-splitting scheme in the &lt;span class="caps"&gt;TT&lt;/span&gt;/&lt;span class="caps"&gt;MPS&lt;/span&gt; format&lt;/a&gt; is a natural way 
to computing dynamics of quantum spin systems Hamiltonians with long-range interaction. We have proposed a unified 
approach that leads to a cheap and efficient computational scheme that can be applied to any Hamiltonian, 
represented in the &lt;span class="caps"&gt;MPO&lt;/span&gt;/&lt;span class="caps"&gt;TT&lt;/span&gt; form.
&lt;img width="600" class="center" src="/images/jutho.png"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1408.5056"&gt;Preprint on&amp;nbsp;arXiv&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="paper"></category></entry><entry><title>Time integration of tensor trains</title><link href="/news/time-integration-of-tensor-trains/" rel="alternate"></link><published>2014-08-07T00:00:00+04:00</published><author><name>Ivan Oseledets</name></author><id>tag:,2014-08-07:news/time-integration-of-tensor-trains/</id><summary type="html">&lt;p&gt;Dynamical low-rank approximation is an efficient framework for solving continious and discrete-time 
problems in high-dimensions. Using the Dirac-Frenkel principle applied to the tensor-train format, 
we have propose a robust and efficient time integrator for the resulting system of nonlinear&amp;nbsp;equations.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1407.2042"&gt;Preprint on&amp;nbsp;arXiv&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Algorithm scheme&lt;/th&gt;
&lt;th&gt;Approximate Laplace inversion&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;img width="300" class="center" src="/images/sweep.png"&gt;&lt;/td&gt;
&lt;td&gt;&lt;img width="300" class="center" src="/images/optim.png"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;</summary><category term="paper"></category></entry><entry><title>Multidimensional integrals in ion-atom collisions</title><link href="/news/multidimensional-integrals-in-ion-atom-collisions/" rel="alternate"></link><published>2014-03-19T00:00:00+04:00</published><author><name>Ivan Oseledets</name></author><id>tag:,2014-03-19:news/multidimensional-integrals-in-ion-atom-collisions/</id><summary type="html">&lt;p&gt;Simulation in physics is full of multidimensional integrals. In the paper &lt;a href="http://arxiv.org/abs/1403.4068"&gt;&lt;span class="caps"&gt;M. S.&lt;/span&gt; Litsarev and &lt;span class="caps"&gt;I. V.&lt;/span&gt; Oseledets. Low rank approximations for the &lt;span class="caps"&gt;DEPOSIT&lt;/span&gt; computer code. arXiv preprint 1403.4068, 2014&lt;/a&gt; we consider the
&lt;a href="http://www.sciencedirect.com/science/article/pii/S0010465512003153"&gt;&lt;span class="caps"&gt;DEPOSIT&lt;/span&gt; code&lt;/a&gt; that is suited 
for the computation of ion-atomic collisons. The main computational bottleneck is the computation 
of a three-dimensional integral. We exploit its structure by computing low-rank separated representation
using cross approximation for a two-dimensional function, and exponential sums approach for the Slater density 
function. 
Implementation of this technique decreases the total computational
time by a &lt;strong&gt;factor of 1000&lt;/strong&gt;. What is more important, the general concept can be applied to more complicated models
(like ion-molecule&amp;nbsp;collision).&lt;/p&gt;
&lt;p&gt;$&amp;nbsp;\&lt;/p&gt;
&lt;div class="math"&gt;\begin{array}{cccccc}
\\hline
\\hline
System &amp;amp;  \\gamma\mbox{-Shell} &amp;amp;  N_w  &amp;amp;  T_s  ( \\times10^{-3}  sec) &amp;amp;  T_{D}  (sec) &amp;amp;  T_{D}/T_s   \\\\
\\hline
 Au^{26+}+ O  &amp;amp;  4df^{17}  &amp;amp;  74  &amp;amp;  7.94  &amp;amp;  3.89  &amp;amp;  490   \\\\
 &amp;amp;  4sp^{8}  &amp;amp;  69  &amp;amp;  4.92  &amp;amp;  3.83  &amp;amp;  778   \\\\
 &amp;amp;  3d^{10}  &amp;amp;  73  &amp;amp;  3.59  &amp;amp;  3.88  &amp;amp;  1080   \\\\
 &amp;amp;  3sp^{8}  &amp;amp;  72  &amp;amp;  3.81  &amp;amp;  3.82  &amp;amp;  1003   \\\\ 
 &amp;amp;  2sp^{8}  &amp;amp;  107  &amp;amp;  2.42  &amp;amp;  3.86  &amp;amp;  1592   \\\\
 &amp;amp;  1sp^{2}  &amp;amp;  209  &amp;amp;  1.24  &amp;amp;  3.88  &amp;amp;  3120   \\\\  
\\hline
 U^{28+}+ Xe  &amp;amp;  5sp^{4}  &amp;amp;  62  &amp;amp;  10.1  &amp;amp;  3.94  &amp;amp;  390  \\\\
 &amp;amp;  4df^{24}  &amp;amp;  70  &amp;amp;  6.05  &amp;amp;  3.90  &amp;amp;  644  \\\\
 &amp;amp;  4sp^{8}  &amp;amp;  67  &amp;amp;  5.00  &amp;amp;  3.94  &amp;amp;  788  \\\\
 &amp;amp;  3d^{10}  &amp;amp;  71  &amp;amp;  3.88  &amp;amp;  3.92  &amp;amp;  1011  \\\\
 &amp;amp;  3sp^{8}  &amp;amp;  70  &amp;amp;  3.52  &amp;amp;  3.90  &amp;amp;  1106  \\\\
 &amp;amp;  2sp^{8}  &amp;amp;  105  &amp;amp;  1.99  &amp;amp;  3.87  &amp;amp;  1945  \\\\
 &amp;amp;  1sp^{2}  &amp;amp;  207  &amp;amp;  1.04  &amp;amp;  3.88  &amp;amp;  3723  \\\\
\\hline
\\hline
\\end{array}&lt;/div&gt;
&lt;p&gt;
$&lt;/p&gt;
&lt;p&gt;Time for the old code (&lt;span class="math"&gt;\(T_D)\)&lt;/span&gt; versus the time for the new code (&lt;span class="math"&gt;\(T_s\)&lt;/span&gt;).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1403.4068"&gt;Preprint on&amp;nbsp;arXiv&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="paper"></category></entry><entry><title>Preconditioners for hierarchical matrices</title><link href="/news/preconditioners-for-hierarchical-matrices/" rel="alternate"></link><published>2014-03-12T00:00:00+04:00</published><author><name>Ivan Oseledets</name></author><id>tag:,2014-03-12:news/preconditioners-for-hierarchical-matrices/</id><summary type="html">&lt;p&gt;We continue to develop our &lt;a href="https://bitbucket.org/muxas/h2tools"&gt;h2tools&lt;/a&gt; package with the new functionality.
The solution of linear systems with hierarchical matrices plays a crucial role in many applications. 
We use the sparse extended form of the H2-matrices to reduce the initial linear system to a block-structured
linear system and then use this block structure to construct different preconditioners. The most efficient
preconditioner is the preconditioner based on the 
so-called &lt;a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3465730/"&gt;&amp;#8220;reverse-Schur complement&amp;#8221;&lt;/a&gt; method: we solve
the initial system using the availability of the fast matrix-by-vector product, and to solve the corretion equation&lt;br /&gt;
we construct the extended system and make several preconditioned iterative steps with&amp;nbsp;it. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1412.1253"&gt;Preprint on&amp;nbsp;arXiv&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="paper"></category></entry><entry><title>Convolution via cross approximation</title><link href="/news/convolution-via-cross-approximation/" rel="alternate"></link><published>2014-02-25T00:00:00+04:00</published><author><name>Ivan Oseledets</name></author><id>tag:,2014-02-25:news/convolution-via-cross-approximation/</id><summary type="html">&lt;p&gt;Multidimensional convolution plays a crucial role in many 
applications. We have proposed a new method for approximate computation of the convolution 
in &lt;em&gt;low-rank tensor formats&lt;/em&gt;
that is based on the
&lt;em&gt;cross approximation&lt;/em&gt; in the frequency domain. 
The method is applicable to any &lt;span class="caps"&gt;SVD&lt;/span&gt;-based tensor format (skeleton, Tucker,  Tensor Train, Hierachical Tucker).
We have computed Newton potentials of different electronic densities, and also presented preliminary 
results for the solution of the Hartree-Fock equation on tensor product grids.
For a practically interesting range of one-dimensional grid sizes &lt;span class="math"&gt;\(n \sim 10^{3}-10^{5}\)&lt;/span&gt; our algorithm is&amp;nbsp;faster.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;He density&lt;/th&gt;
&lt;th&gt;H2 density&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;img width="270" class="center" src="/images/He_density.jpg"&gt;&lt;/td&gt;
&lt;td&gt;&lt;img width="270" class="center" src="/images/H2_density.jpg"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1402.5649"&gt;Preprint on&amp;nbsp;arXiv&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/rakhuba/tucker3d"&gt;MiniTucker Toolbox on&amp;nbsp;Github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://bitbucket.org/rakhuba/crossconv-experiment"&gt;Data from the paper on&amp;nbsp;Bitbucket&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="paper"></category></entry><entry><title>Theses topics</title><link href="/news/theses-topics/" rel="alternate"></link><published>2014-02-13T00:00:00+04:00</published><author><name>Ivan Oseledets</name></author><id>tag:,2014-02-13:news/theses-topics/</id><summary type="html">&lt;p&gt;I have put short descriptions of the available student
project online. &lt;a href="/theses/"&gt;Please&amp;nbsp;check&lt;/a&gt;&lt;/p&gt;</summary><category term="Students"></category></entry><entry><title>Happy new year!</title><link href="/news/happy-new-year/" rel="alternate"></link><published>2013-01-09T00:21:00+04:00</published><author><name>Admin</name></author><id>tag:,2013-01-09:news/happy-new-year/</id><summary type="html">&lt;p&gt;2013 is now in its full rights, so it is time to go on with research.
With &lt;a class="reference external" href="http://na.uni-tuebingen.de/~lubich/"&gt;Christian Lubich&lt;/a&gt; we have finished a &lt;a class="reference external" href="http://arxiv.org/abs/1301.1058"&gt;paper on a very efficient
time-stepping scheme for the dynamical low-rank approximation&lt;/a&gt; &amp;#8212;-
so-called &lt;span class="caps"&gt;KLS&lt;/span&gt;-scheme, which is remarkably simple but efficient to
compute the dynamics on low-rank manifolds. It presents a full analysis
for the two-dimensional case, with multidimensional case (&lt;span class="caps"&gt;TT&lt;/span&gt;-format) in&amp;nbsp;progress.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Hello&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
</summary><category term="paper"></category></entry><entry><title>One more paper</title><link href="/news/one-more-paper/" rel="alternate"></link><published>2012-12-22T22:52:00+04:00</published><author><name>Admin</name></author><id>tag:,2012-12-22:news/one-more-paper/</id><summary type="html">&lt;p&gt;One more old paper on &lt;a class="reference external" href="http://dx.doi.org/10.1007/s00365-012-9175-x"&gt;explicit representations of simple functions in
tensor formats&lt;/a&gt; is published in the Constructive&amp;nbsp;Approximation!&lt;/p&gt;
</summary><category term="paper"></category></entry><entry><title>Solving parabolic systems (with application to Fokker-Planck)</title><link href="/news/solving-parabolic-systems-with-application-to-fokker-planck/" rel="alternate"></link><published>2012-12-14T09:57:00+04:00</published><author><name>Admin</name></author><id>tag:,2012-12-14:news/solving-parabolic-systems-with-application-to-fokker-planck/</id><summary type="html">&lt;p&gt;Our paper on the new time-stepping scheme based on the &lt;span class="caps"&gt;QTT&lt;/span&gt;-format &lt;a class="reference external" href="http://dx.doi.org/10.1137/120864210"&gt;has
been published&lt;/a&gt; in &lt;span class="caps"&gt;SISC&lt;/span&gt;!&lt;/p&gt;
</summary><category term="paper"></category></entry><entry><title>News</title><link href="/news/news/" rel="alternate"></link><published>2012-10-14T13:42:00+04:00</published><author><name>Admin</name></author><id>tag:,2012-10-14:news/news/</id><summary type="html">&lt;p&gt;Four papers are in&amp;nbsp;progress : on&amp;nbsp;the block eigenvalue solver in&amp;nbsp;the
&lt;span class="caps"&gt;TT&lt;/span&gt;-format, on&amp;nbsp;the dynamical low-rank approximation, on&amp;nbsp;the tensor
structure of&amp;nbsp;the wavelet tensor train matrix and on&amp;nbsp;the fast solution
of&amp;nbsp;the Stokes problem in&amp;nbsp;tensor format. Hope to finish them&amp;nbsp;soon.&lt;/p&gt;
&lt;/p&gt;&lt;p&gt;Also, I&amp;nbsp;put some time to&amp;nbsp;get an&amp;nbsp;implementation of&amp;nbsp;the &lt;span class="caps"&gt;TT&lt;/span&gt;-Toolbox
in&amp;nbsp;Python. &lt;a class="reference external" href="http://github.com/oseledets/ttpy"&gt;The preliminary version (ttpy 0.1) is&amp;nbsp;available on&amp;nbsp;the
github.&lt;/a&gt; Please take a&amp;nbsp;look on&amp;nbsp;it, if&amp;nbsp;you are&amp;nbsp;interested.&lt;/p&gt;
&lt;/p&gt;</summary></entry><entry><title>Publications of our group</title><link href="/news/publications-of-our-group/" rel="alternate"></link><published>2012-07-17T20:46:00+04:00</published><author><name>Admin</name></author><id>tag:,2012-07-17:news/publications-of-our-group/</id><summary type="html">&lt;p&gt;We have recently put the publications of our research group at the
Institute of Numerical Mathematics &lt;span class="caps"&gt;RAS&lt;/span&gt; on the web. The list is not yet
full, but is close. &lt;a class="reference external" href="http://pub.inm.ras.ru"&gt;Check&amp;nbsp;it!&lt;/a&gt;&lt;/p&gt;
&lt;/p&gt;</summary></entry><entry><title>Fast adaptive interpolation of multidimensional arrays in TT-format</title><link href="/news/fast-adaptive-interpolation-of-multidimensional-arrays-in-tt-format/" rel="alternate"></link><published>2012-06-15T12:59:00+04:00</published><author><name>Admin</name></author><id>tag:,2012-06-15:news/fast-adaptive-interpolation-of-multidimensional-arrays-in-tt-format/</id><summary type="html">&lt;p&gt;&lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=29"&gt;This paper&lt;/a&gt; with Dmitry Savostyanov published in&amp;nbsp;the end of&amp;nbsp;2011
in&amp;nbsp;the Proceedings of&amp;nbsp;7th International Workshop on&amp;nbsp;Multidimensional
Systems (nDS), doi: &lt;a class="reference external" href="http://dx.doi.org/10.1109/nDS.2011.6076873"&gt;10.1109/nDS.2011.6076873&lt;/a&gt;&amp;nbsp;is about fast adaptive
methods for the approximation of&amp;nbsp;high-dimensional arrays by&amp;nbsp;cross-type
methods (such methods are quite popular for&amp;nbsp;matrices).&lt;/p&gt;
&lt;div&gt;&lt;p&gt;The method of&amp;nbsp;&lt;span class="caps"&gt;TT&lt;/span&gt;-ranks adaptation is&amp;nbsp;based on&amp;nbsp;the &lt;span class="caps"&gt;DMRG&lt;/span&gt;-scheme, which
is&amp;nbsp;a&amp;nbsp;“universal tool” for &lt;span class="caps"&gt;TT&lt;/span&gt;-methods. A&amp;nbsp;prototype implementation (quite
messy, but working) is&amp;nbsp;available in&amp;nbsp;the &lt;a class="reference external" href="https://github.com/oseledets/TT-Toolbox/blob/master/cross/dmrg_cross.m"&gt;Github repository of&amp;nbsp;the
&lt;span class="caps"&gt;TT&lt;/span&gt;-Toolbox&lt;/a&gt;. To&amp;nbsp;make it&amp;nbsp;work, you should install the &lt;a class="reference external" href="http://github.com/oseledets/TT-Toolbox"&gt;&lt;span class="caps"&gt;TT&lt;/span&gt;-Toolbox&lt;/a&gt;&amp;nbsp;itself.&lt;/p&gt;
&lt;/div&gt;&lt;/p&gt;</summary></entry><entry><title>Dynamical TT-approximation</title><link href="/news/dynamical-tt-approximation/" rel="alternate"></link><published>2012-04-25T23:17:00+04:00</published><author><name>Admin</name></author><id>tag:,2012-04-25:news/dynamical-tt-approximation/</id><summary type="html">&lt;div&gt;&lt;/p&gt;&lt;p&gt;Dynamical low-rank approximation is&amp;nbsp;a&amp;nbsp;rather new and important topic,
which was studied by&amp;nbsp;Lubich and Koch for low-rank matrices and low-rank
(in&amp;nbsp;the sense of&amp;nbsp;Tucker format) tensor decomposition. Such kind
of&amp;nbsp;techniques were well known in&amp;nbsp;physics in&amp;nbsp;chemistry, going back
to&amp;nbsp;Dirac-Frenkel principle, and &lt;span class="caps"&gt;MCTDH&lt;/span&gt; method for the computation
of&amp;nbsp;quantum molecular vibrations. It&amp;nbsp;was interesting to&amp;nbsp;extend this
approach to&amp;nbsp;the &lt;span class="caps"&gt;TT&lt;/span&gt;-format.&lt;/p&gt;
&lt;/p&gt;&lt;p&gt;&lt;/div&gt;&lt;/p&gt;&lt;p&gt;We&amp;nbsp;did it&amp;nbsp;in&amp;nbsp;our recent paper&lt;a class="reference external" href="http://www.mis.mpg.de/preprints/2012/preprint2012_24.pdf"&gt;**Efficient time-stepping scheme for
dynamics on&amp;nbsp;&lt;span class="caps"&gt;TT&lt;/span&gt;-manifolds**&lt;/a&gt;, which is&amp;nbsp;published as&amp;nbsp;a&amp;nbsp;preprint in&amp;nbsp;&lt;span class="caps"&gt;MIS&lt;/span&gt;
&lt;span class="caps"&gt;MPI&lt;/span&gt;&amp;nbsp;Leipzig. In&amp;nbsp;fact, we&amp;nbsp;managed to&amp;nbsp;provide an&amp;nbsp;efficient numerical
scheme for the computation of&amp;nbsp;the &lt;span class="caps"&gt;TT&lt;/span&gt;-dynamics. The &lt;span class="caps"&gt;MATLAB&lt;/span&gt; implementation
will be&amp;nbsp;soon included in&amp;nbsp;the development &lt;a class="reference external" href="http://github.com/oseledets/TT-Toolbox"&gt;github repository of&amp;nbsp;the
&lt;span class="caps"&gt;TT&lt;/span&gt;-Toolbox&lt;/a&gt;.&lt;/p&gt;
&lt;/p&gt;</summary></entry><entry><title>TT-Toolbox 2.2.</title><link href="/news/tt-toolbox-22/" rel="alternate"></link><published>2012-02-08T22:07:00+04:00</published><author><name>Admin</name></author><id>tag:,2012-02-08:news/tt-toolbox-22/</id><summary type="html">&lt;p&gt;&lt;span class="caps"&gt;TT&lt;/span&gt;-Toolbox (&lt;span class="caps"&gt;TT&lt;/span&gt;=Tensor Train) Version&amp;nbsp;2.2&lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;TT&lt;/span&gt;(Tensor Train) format is an efficient way for&amp;nbsp;low-parametric&lt;/p&gt;
&lt;p&gt;representation of high-dimensional tensors. The &lt;span class="caps"&gt;TT&lt;/span&gt;-Toolbox&lt;/p&gt;
&lt;p&gt;is a &lt;span class="caps"&gt;MATLAB&lt;/span&gt; implementation of basic operations&amp;nbsp;with&lt;/p&gt;
&lt;p&gt;tensors in &lt;span class="caps"&gt;TT&lt;/span&gt;-format. It&amp;nbsp;includes:&lt;/p&gt;
&lt;p&gt;* tt_tensor and tt_matrix classes for storing vectors and&amp;nbsp;operators&lt;/p&gt;
&lt;p&gt;* Basic linear algebra subroutines (addition, matrix-by-vector&amp;nbsp;product,&lt;/p&gt;
&lt;p&gt;elementwise multiplication and many others) using standard &lt;span class="caps"&gt;MATLAB&lt;/span&gt;&amp;nbsp;syntax,&lt;/p&gt;
&lt;p&gt;linear complexity in the dimension, reshape&amp;nbsp;function&lt;/p&gt;
&lt;p&gt;* Fast rounding procedure with a prescribed&amp;nbsp;accuracy&lt;/p&gt;
&lt;p&gt;* Advanced approximation and solution&amp;nbsp;techniques:&lt;/p&gt;
&lt;/p&gt;&lt;p&gt;* Approximate solution of linear systems and eigenvalue&amp;nbsp;problems&lt;/p&gt;
&lt;p&gt;* Cross methods to approximate &amp;#8220;black-box&amp;#8221;&amp;nbsp;tensors&lt;/p&gt;
&lt;p&gt;* Wavelet tensor train&amp;nbsp;decomposition&lt;/p&gt;
&lt;/p&gt;&lt;p&gt;* Construction of basic operators and functions (Laplace operator,
function of a &lt;span class="caps"&gt;TT&lt;/span&gt;-tensor)&lt;/p&gt;
&lt;p&gt;* Computation of maximal and minimal elements of a&amp;nbsp;tensor&lt;/p&gt;
&lt;p&gt;* and several&amp;nbsp;others&lt;/p&gt;
&lt;/p&gt;&lt;p&gt;New in Version&amp;nbsp;2.2&lt;/p&gt;
&lt;p&gt;* Better&amp;nbsp;documentation&lt;/p&gt;
&lt;p&gt;* Mixed &lt;span class="caps"&gt;QTT&lt;/span&gt;-Tucker format (qtt_tucker&amp;nbsp;class)&lt;/p&gt;
&lt;p&gt;* reshape function for a &lt;span class="caps"&gt;TT&lt;/span&gt;-tensor/&lt;span class="caps"&gt;TT&lt;/span&gt;-matrix&lt;/p&gt;
&lt;p&gt;* dmrg_cross method for black-box tensor&amp;nbsp;approximation&lt;/p&gt;
&lt;p&gt;* Convolution in &lt;span class="caps"&gt;QTT&lt;/span&gt;-format&lt;/p&gt;
&lt;/p&gt;&lt;p&gt;[drain file 9 url&amp;nbsp;You can get it here: &lt;strong&gt;&lt;span class="caps"&gt;TT&lt;/span&gt;-Toolbox 2.2.&amp;nbsp;]&lt;/strong&gt;&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;If you are interested in getting the current &amp;#8220;development&amp;#8221; version of
the Toolbox, take a look at the github repository
&lt;a class="reference external" href="http://github.com/oseledets/TT-Toolbox"&gt;http://github.com/oseledets/&lt;span class="caps"&gt;TT&lt;/span&gt;-Toolbox/&lt;/a&gt;&lt;/p&gt;
</summary></entry><entry><title>Google My citations</title><link href="/news/google-my-citations/" rel="alternate"></link><published>2011-12-04T21:10:00+04:00</published><author><name>Admin</name></author><id>tag:,2011-12-04:news/google-my-citations/</id><summary type="html">&lt;p&gt;Google mycitations service looks great. &lt;a class="reference external" href="http://scholar.google.com/citations?user=5kMqBQEAAAAJ&amp;amp;hl=en"&gt;Here is&amp;nbsp;mine&lt;/a&gt;&lt;/p&gt;
</summary></entry><entry><title>Twitter</title><link href="/news/twitter/" rel="alternate"></link><published>2011-11-26T16:43:00+04:00</published><author><name>Admin</name></author><id>tag:,2011-11-26:news/twitter/</id><summary type="html">&lt;p&gt;I decided to by on a twitter also (now posts only in Russian, but who
knows :)&amp;nbsp;)&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://twitter.com/oseledetsivan"&gt;oseledetsivan&lt;/a&gt;&lt;/p&gt;
</summary></entry><entry><title>Tensor-Train decomposition paper finally published!</title><link href="/news/tensor-train-decomposition-paper-finally-published/" rel="alternate"></link><published>2011-09-26T11:33:00+04:00</published><author><name>Admin</name></author><id>tag:,2011-09-26:news/tensor-train-decomposition-paper-finally-published/</id><summary type="html">&lt;p&gt;Finally, after more than 2&amp;nbsp;years of&amp;nbsp;reviewing process, the basic paper
on&amp;nbsp;the &lt;span class="caps"&gt;TT&lt;/span&gt;-format is&amp;nbsp;published in&amp;nbsp;&lt;span class="caps"&gt;SISC&lt;/span&gt;!&lt;/p&gt;
&lt;p&gt;You can get the journal version &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=28"&gt;here&lt;/a&gt; or&amp;nbsp;directly at&amp;nbsp;the &lt;a class="reference external" href="http://dx.doi.org/10.1137/090752286"&gt;&lt;span class="caps"&gt;SIAM&lt;/span&gt;&amp;nbsp;website&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The first text was based on&amp;nbsp;the paper “Compact matrix form of&amp;nbsp;the
d-dimensional tensor decomposition”. However, it&amp;nbsp;has improved
(I&amp;nbsp;believe) a&amp;nbsp;lot, and can be&amp;nbsp;considered as&amp;nbsp;as&amp;nbsp;separate&amp;nbsp;paper.&lt;/p&gt;
&lt;p&gt;Also, this paper is&amp;nbsp;the first one, where my&amp;nbsp;1-year old daugther Nastya
has written a&amp;nbsp;small part: look at&amp;nbsp;the Algorithm&amp;nbsp;2, step 2&amp;nbsp;at the end.
These slashes were typed by&amp;nbsp;her, but&amp;nbsp;I only noticed it&amp;nbsp;after publishing&amp;nbsp;:)&lt;/p&gt;
</summary></entry><entry><title>Solution of linear systems in the TT-format</title><link href="/news/solution-of-linear-systems-in-the-tt-format/" rel="alternate"></link><published>2011-05-05T22:13:00+04:00</published><author><name>Admin</name></author><id>tag:,2011-05-05:news/solution-of-linear-systems-in-the-tt-format/</id><summary type="html">&lt;p&gt;The new paper, &lt;span class="caps"&gt;S.V.&lt;/span&gt; Dolgov, &lt;span class="caps"&gt;I.V.&lt;/span&gt; Oseledets, &lt;a class="reference external" href="http://www.mis.mpg.de/preprints/2011/preprint2011_19.pdf"&gt;Solution of&amp;nbsp;linear systems
and matrix inversion in&amp;nbsp;the &lt;span class="caps"&gt;TT&lt;/span&gt;-format&lt;/a&gt; describes a&amp;nbsp;&lt;span class="caps"&gt;DMRG&lt;/span&gt;-type method for
the solution of&amp;nbsp;linear systems with both the matrix and the tensor
in&amp;nbsp;the &lt;span class="caps"&gt;TT&lt;/span&gt;-format. The method is&amp;nbsp;able to&amp;nbsp;solve certain structured linear
systems of&amp;nbsp;order 2^d, where d&amp;nbsp;can be&amp;nbsp;of&amp;nbsp;order several hundreds, and
&lt;span class="caps"&gt;TT&lt;/span&gt;-ranks can be&amp;nbsp;of&amp;nbsp;order tensor or&amp;nbsp;hundreds. The solver is&amp;nbsp;available
as&amp;nbsp;a&amp;nbsp;part of&amp;nbsp;the &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/?page_id=24"&gt;&lt;span class="caps"&gt;TT&lt;/span&gt;-Toolbox 2.1&lt;/a&gt;. Moreover, some test data of&amp;nbsp;the
article can be&amp;nbsp;downloaded (the new Toolbox is&amp;nbsp;required to&amp;nbsp;be&amp;nbsp;installed).
You can download it&amp;nbsp;from the page &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/?page_id=89"&gt;Benchmarks and data&lt;/a&gt; or&amp;nbsp;[drain file
8&amp;nbsp;url directly download test data as&amp;nbsp;gzipped tar archive] This archive
contains .mat files with A,x,rhs, where&amp;nbsp;A is&amp;nbsp;a&amp;nbsp;&lt;span class="caps"&gt;TT&lt;/span&gt;-matrix, rhs
is&amp;nbsp;a&amp;nbsp;&lt;span class="caps"&gt;TT&lt;/span&gt;-vector (&lt;span class="caps"&gt;TT&lt;/span&gt;-tensor), x&amp;nbsp;is&amp;nbsp;an&amp;nbsp;approximate solution of&amp;nbsp;A*x = rhs.
You can check this directly by&amp;nbsp;computing in&amp;nbsp;&lt;span class="caps"&gt;MATLAB&lt;/span&gt; norm(A*x&amp;nbsp;—
rhs)/norm(rhs) Be&amp;nbsp;aware, that computing full(A) is&amp;nbsp;prohibitive for all
examples, but full(x) or&amp;nbsp;full(rhs) sometimes is&amp;nbsp;not! I&amp;nbsp;plan to&amp;nbsp;add more
benchmarking data to&amp;nbsp;this page, with more &lt;span class="caps"&gt;TT&lt;/span&gt;-matrices and &lt;span class="caps"&gt;TT&lt;/span&gt;-vectors.&lt;/p&gt;
</summary></entry><entry><title>TT-Toolbox 2.1</title><link href="/news/tt-toolbox-21/" rel="alternate"></link><published>2011-05-04T18:18:00+04:00</published><author><name>Admin</name></author><id>tag:,2011-05-04:news/tt-toolbox-21/</id><summary type="html">&lt;p&gt;&lt;span class="caps"&gt;TT&lt;/span&gt;-Toolbox 2.1 is released. It contains several bug fixes. My great
thanks to Sergey Dolgov for writing many important routines and to
Vladimir Kazeev for providing his code for the construction of the
&lt;span class="caps"&gt;QTT&lt;/span&gt;-representation of discrete Laplace operator (it can be done for
extremely high dimensions in a&amp;nbsp;second!).&lt;/p&gt;
&lt;/p&gt;&lt;p&gt;&lt;span class="caps"&gt;TT&lt;/span&gt;-Toolbox 2.1 can be downloaded from [drain file 6 url here] or from
&lt;a class="reference external" href="http://spring.inm.ras.ru/osel/?page_id=24"&gt;the&amp;nbsp;page&lt;/a&gt;&lt;/p&gt;
&lt;/p&gt;&lt;p&gt;The [drain file 7 url short introduction] can be also&amp;nbsp;downloaded.&lt;/p&gt;
&lt;/p&gt;&lt;p&gt;All comments and suggestions are welcome. In the next release we plan to
add the conversion procedures from the T. Kolda/B. Bader Tensor Toolbox
(conversion from ktensor and sptensor classes), and also to provide more
benchmarking&amp;nbsp;examples.&lt;/p&gt;
&lt;/p&gt;</summary></entry><entry><title>TT-Toolbox 2.0</title><link href="/news/tt-toolbox-20/" rel="alternate"></link><published>2011-03-05T14:34:00+03:00</published><author><name>Admin</name></author><id>tag:,2011-03-05:news/tt-toolbox-20/</id><summary type="html">&lt;p&gt;New version of &lt;span class="caps"&gt;TT&lt;/span&gt;-Toolbox is&amp;nbsp;released.&lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;TT&lt;/span&gt; Toolbox version 2.0 introduces several major innovations compared to
version&amp;nbsp;1.0.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;New classes tt_tensor and tt_matrix, which now represent &lt;span class="caps"&gt;TT&lt;/span&gt;-tensors
and &lt;span class="caps"&gt;TT&lt;/span&gt;-matrices.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Object-oriented approach allowed to overload many standard &lt;span class="caps"&gt;MATLAB&lt;/span&gt;
functions, including addition,&amp;nbsp;subtraction,&lt;/p&gt;
&lt;/p&gt;&lt;p&gt;&lt;p&gt;multiplication by number, scalar product, norm, Kronecker products,
matrix-by-vector product&amp;nbsp;etc&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Complex arithmetics is&amp;nbsp;supported&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Several subroutines to generate basic &lt;span class="caps"&gt;TT&lt;/span&gt;-tensors and &lt;span class="caps"&gt;TT&lt;/span&gt;-matrices:
matrices of all ones, identity&amp;nbsp;matrix,&lt;/p&gt;
&lt;/p&gt;&lt;p&gt;&lt;p&gt;random &lt;span class="caps"&gt;TT&lt;/span&gt;-tensors with fixed core&amp;nbsp;sizes&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Advances operations, like computation of F(&lt;span class="caps"&gt;TT&lt;/span&gt;) using cross method,
matrix-by-vector product using Krylov methods, dmrg solver for linear&amp;nbsp;systems&amp;#8230;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/p&gt;&lt;p&gt;&lt;span class="caps"&gt;TT&lt;/span&gt;-Toolbox 2.0 can be &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/?page_id=24"&gt;downloaded from this page&lt;/a&gt;, or [drain file 4 url&amp;nbsp;directly].&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=27"&gt;Brief introduction to functionality and&amp;nbsp;changes&lt;/a&gt;&lt;/p&gt;
</summary></entry><entry><title>DMRG+QTT</title><link href="/news/dmrgqtt/" rel="alternate"></link><published>2010-11-19T03:13:00+03:00</published><author><name>Admin</name></author><id>tag:,2010-11-19:news/dmrgqtt/</id><summary type="html">&lt;p&gt;&lt;span class="caps"&gt;DMRG&lt;/span&gt; (Density Matrix Renormalization Group) is a very efficient
algorithm for computation of low-lying eigenstates of quantum spin
systems. &lt;span class="caps"&gt;QTT&lt;/span&gt; (Quantics Tensor Train) consists in tensorization of
one-dimensional objects (i.e. vectors of values of function on a grid
with 2^d points) into a d-dimensional tensor, and application of Tensor
Train (&lt;span class="caps"&gt;TT&lt;/span&gt;) format to such tensor. What do they have in common? Check our
new paper, &lt;a class="reference external" href="http://www.mis.mpg.de/preprints/2010/preprint2010_69.pdf"&gt;&lt;span class="caps"&gt;DMRG&lt;/span&gt;+&lt;span class="caps"&gt;QTT&lt;/span&gt; approach to high-dimensional quantum molecular&amp;nbsp;dynamics&lt;/a&gt;&lt;/p&gt;
</summary></entry><entry><title>Tensor Train in a nutshell</title><link href="/news/tensor-train-in-a-nutshell/" rel="alternate"></link><published>2010-11-02T21:12:00+03:00</published><author><name>Admin</name></author><id>tag:,2010-11-02:news/tensor-train-in-a-nutshell/</id><summary type="html">&lt;p&gt;I have written a &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=26"&gt;one-page article that describes vital operations in
&lt;span class="caps"&gt;TT&lt;/span&gt;-format&lt;/a&gt;. Hope you will find it convincing, that &lt;span class="caps"&gt;TT&lt;/span&gt;-format is indeed
a very elegant representation for&amp;nbsp;tensors.&lt;/p&gt;
</summary></entry><entry><title>Relation of tensors, quantics TT and wavelet tensor trains</title><link href="/news/relation-of-tensors-quantics-tt-and-wavelet-tensor-trains/" rel="alternate"></link><published>2010-10-03T08:36:00+04:00</published><author><name>Admin</name></author><id>tag:,2010-10-03:news/relation-of-tensors-quantics-tt-and-wavelet-tensor-trains/</id><summary type="html">&lt;p&gt;In our paper &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=25"&gt;Algebraic wavelet transform via quantics tensor train
decomposition&lt;/a&gt; we show, how quantics tensor train approach, which
consists in tensorization of vectors and matrices, can be interpreted as
&lt;em&gt;algebraic wavelet transform&lt;/em&gt;. Advantages are especially clear for two
dimensional functions. Besides new results, this approach, called &lt;span class="caps"&gt;WTT&lt;/span&gt;
(wavelet tensor trains) describes several open and interesting&amp;nbsp;problems&lt;/p&gt;
&lt;/p&gt;</summary></entry><entry><title>Preprint 2010-04: Explicit tensor-train representation of certain functions</title><link href="/news/preprint-2010-04-explicit-tensor-train-representation-of-certain-functions/" rel="alternate"></link><published>2010-08-28T09:35:00+04:00</published><author><name>Admin</name></author><id>tag:,2010-08-28:news/preprint-2010-04-explicit-tensor-train-representation-of-certain-functions/</id><summary type="html">&lt;p&gt;The aim of &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=24"&gt;Preprint 2010-04&lt;/a&gt; is to construct explicit tensor-train
representations for certain function-related tensors and vectors, which
are constructed on the basis of introduced &lt;em&gt;functional tensor train
decomposition.&lt;/em&gt;These results are then used to construct explicit
quantics tensor train decomposition for polynomial and sine&amp;nbsp;functions.&lt;/p&gt;
</summary></entry><entry><title>Krylov methods for tensors</title><link href="/news/krylov-methods-for-tensors/" rel="alternate"></link><published>2010-04-12T21:48:00+04:00</published><author><name>Admin</name></author><id>tag:,2010-04-12:news/krylov-methods-for-tensors/</id><summary type="html">&lt;p&gt;Using Wedderburn rank-reduction formulae (for reference what is that,
please read a &lt;a class="reference external" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.66.8644&amp;amp;rep=rep1&amp;amp;type=pdf"&gt;nice paper by Gene Golub and Moody Chu&lt;/a&gt;) , we managed to
create several robust Krylov methods for the approximation of
three-dimensional tensors. It is a preprint &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=23"&gt;2010-1&lt;/a&gt; of Institute of
Numerical Mathematics. A new general interpretation is given for
rank-revealing methods, which use only matrix-by-vector and
tensor-by-vector-by-vector products. This seems to be also a new (and
simple) derivation of the Lanczos&amp;nbsp;algorithm.&lt;/p&gt;
&lt;p&gt;These methods are very crucial for sparse structured tensors (as
pioneered by the work of Elden and Savas), but they become critical for
the approximation of structured tensor operatiions, for example for the
compression of matrix-by-vector product, where both matrix and vector
are in the Tucker format. In the sequel that is under preparation, these
methods will be extended to &lt;span class="caps"&gt;TT&lt;/span&gt; case, and included in future versions of
&lt;span class="caps"&gt;TT&lt;/span&gt;-Toolbox. This will greatly speed up almost all approximate linear
algebra in it (by a factor of 10 at&amp;nbsp;least).&lt;/p&gt;
</summary></entry><entry><title>Tensor trees and tensor trains</title><link href="/news/tensor-trees-and-tensor-trains/" rel="alternate"></link><published>2009-09-18T19:32:00+04:00</published><author><name>Admin</name></author><id>tag:,2009-09-18:news/tensor-trees-and-tensor-trains/</id><summary type="html">&lt;p&gt;In a &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=22"&gt;new paper&lt;/a&gt;, we expose connections between tensor networks and
recent recursive representations of high-dimensional tensors described
by binary tensor trees and based on a sequence of skeleton (dyadic)
decompositions for special unfolding matrices for a given
tensor.Â&amp;nbsp;Â&amp;nbsp;Â&amp;nbsp;Â&amp;nbsp; As the main result, we prove that a tensor decomposition
by any binary tensor tree with certain restrictions on the distribution
of spatial and auxiliary indices reduces to one and same for a
particular case of tree. Since the latter tree is of simple
predetermined shape, it becomes not needed at all in the construction of
numerical algorithms. The tree input is replaced with a permutation of
spatial indices (modes). The corresponding decomposition is given by the
so-called tensor trains and known as &lt;span class="caps"&gt;TT&lt;/span&gt;&amp;nbsp;decomposition.&lt;/p&gt;
</summary></entry><entry><title>Black box cross approximation for multidimensional arrays</title><link href="/news/black-box-cross-approximation-for-multidimensional-arrays/" rel="alternate"></link><published>2009-07-23T14:15:00+04:00</published><author><name>Admin</name></author><id>tag:,2009-07-23:news/black-box-cross-approximation-for-multidimensional-arrays/</id><summary type="html">&lt;p&gt;In our new paper, &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=21"&gt;&amp;#8220;&lt;span class="caps"&gt;TT&lt;/span&gt; cross approximation for multidimensional
arrays&amp;#8221;&lt;/a&gt; a new formula is presented for the recovery of a
high-dimensional array from a part of its entries, provided that the
array possesses some low-rank structure, namely it has small compression
ranks (for example, a tensor of low canonical rank satisfies this). The
only previous work known to us is the work by Grasedyck, Espig and
Hackbusch, which uses interpolation on &amp;#8220;fiber crosses&amp;#8221;. It is based on
canonical decomposition, requires minimization methods and there is no
guarantee that the method will work even in the exact. Our new
representation solves this problem completely, and it is shown, in
particular, that if the rank of the tensor is r, then it can be exactly
recovered from O(dnr^2) of its entries. This is a natural generalization
of the skeleton decomposition of matrices and it becomes possible due to
the replacement of the canonical format by the &lt;span class="caps"&gt;TT&lt;/span&gt; format, which is
related to a series of matrix decompositions. Â&amp;nbsp; It is also proven that
the &lt;span class="caps"&gt;TT&lt;/span&gt; approximation obtained by a sequence of &lt;span class="caps"&gt;SVD&lt;/span&gt; decompositions can be
worser only up to a factor of \sqrt(d-1)Â&amp;nbsp; then the optimal &lt;span class="caps"&gt;TT&lt;/span&gt;
approximation in the Frobenious&amp;nbsp;norm.&lt;/p&gt;
&lt;p&gt;The simple alternating maxvol algorithm is presented for the computation
of the &lt;span class="caps"&gt;TT&lt;/span&gt;-cross decomposition of a black box tensors, which has
complexity linear in the dimensions, and its effectiveness is
illustratred on several examples inÂ&amp;nbsp; multidimensional integrations,
with dimensions of order hundreds and even thousands. The algorithm is
implemented as part of &lt;span class="caps"&gt;TT&lt;/span&gt; Toolbox and the code will be presented shortly&amp;nbsp;after.&lt;/p&gt;
</summary></entry><entry><title>TT toolbox</title><link href="/news/tt-toolbox/" rel="alternate"></link><published>2009-05-29T18:36:00+04:00</published><author><name>Admin</name></author><id>tag:,2009-05-29:news/tt-toolbox/</id><summary type="html">&lt;p&gt;A first version of &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/?page_id=24"&gt;&lt;span class="caps"&gt;TT&lt;/span&gt; toolbox&lt;/a&gt; for &lt;span class="caps"&gt;MATLAB&lt;/span&gt; is released. It seems to
works also under Octave &amp;#8212;- through not fully tested. Any comments,
suggestions and bug reports are welcome at&amp;nbsp;ivan.oseledets(dog)gmail.com&lt;/p&gt;
&lt;p&gt;All basic algorithms are implemented as a set of short &lt;span class="caps"&gt;MATLAB&lt;/span&gt; functions.
You can try to design your own fast algorithm with these routines or
test if there is indeed a hidden &lt;span class="caps"&gt;TT&lt;/span&gt; structure in your
vector/matrix/tensor. Really high-dimensional black box &lt;span class="caps"&gt;TT&lt;/span&gt; approximation
is underway and will be realized soon in the future versions of &lt;span class="caps"&gt;TT&lt;/span&gt;&amp;nbsp;toolbox.&lt;/p&gt;
&lt;p&gt;The efficient Fortran (or C) versions of the &lt;span class="caps"&gt;TT&lt;/span&gt; toolbox are under
development right&amp;nbsp;now.&lt;/p&gt;
</summary></entry><entry><title>Excluded sums and quasiseparable matrices.</title><link href="/news/excluded-sums-and-quasiseparable-matrices/" rel="alternate"></link><published>2009-05-03T17:45:00+04:00</published><author><name>Admin</name></author><id>tag:,2009-05-03:news/excluded-sums-and-quasiseparable-matrices/</id><summary type="html">&lt;p&gt;The idea of Edelman et al. (published in 2005 in &lt;span class="caps"&gt;SIAM&lt;/span&gt; News) for fast
evaluation of excluded sums and their relation with the non-recursive
multipole method was largely unnoticed. The authors promised to give a
new implementation of the multipole method based on their (quite
elegant) approach however up to now nothing is known. From my point of
view the problem is that they didn&amp;#8217;t succeed with the efficient
implementation of functional approximations. In our &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=19"&gt;new paper&lt;/a&gt; this
idea is fully investigated in the one-dimensional case. It appears that
it can be done in a simple manner by using successive low-rank skeleton
approximation of a matrices in the lower triangular part and in the
upper triangular part of the matrix and it can be shown that the
obtained method works for an arbitrary quasiseparable matrix (i.e.,
matrix where every submatrix strictly below or over the diagonal has low
rank), and moreover, a new representation for the class of
quasiseparable matrices is obtained. This is a first step in the project
&amp;#8220;Matrix methods for the N-body&amp;nbsp;problems&amp;#8221;.&lt;/p&gt;
&lt;p&gt;The future research will go in two directions. The first one concerns
quasiseparable matrices and effective solvers and eigensolvers using the
new representation and the second is the generalization to two or three&amp;nbsp;dimensions.&lt;/p&gt;
</summary></entry><entry><title>Tensors inside of matrices give logarithmic complexity</title><link href="/news/tensors-inside-of-matrices-give-logarithmic-complexity/" rel="alternate"></link><published>2009-05-03T17:37:00+04:00</published><author><name>Admin</name></author><id>tag:,2009-05-03:news/tensors-inside-of-matrices-give-logarithmic-complexity/</id><summary type="html">&lt;p&gt;The recently intoduced &lt;span class="caps"&gt;TT&lt;/span&gt;-format finds a surprising application for the
compression of ordinary &amp;#8220;two&amp;#8221; or &amp;#8220;three&amp;#8221; dimensional matrices, related
to the discretization of operators on tensor grids. For some examples
the complexity is shown to be logarithmic in the matrix order. The new
format (named &lt;span class="caps"&gt;TTM&lt;/span&gt; format) can be used to implement all basic operations
efficiently. The Matlab codes will be posted here soon. The paper itself
is &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=18"&gt;here&lt;/a&gt;&lt;/p&gt;
</summary></entry><entry><title>New tensor decomposition</title><link href="/news/new-tensor-decomposition/" rel="alternate"></link><published>2009-03-15T03:13:00+03:00</published><author><name>Admin</name></author><id>tag:,2009-03-15:news/new-tensor-decomposition/</id><summary type="html">&lt;p&gt;A new paper, &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=17"&gt;A compact matrix form of the d-dimensional tensor
decomposition&lt;/a&gt; is added. A new version of the &lt;span class="caps"&gt;TT&lt;/span&gt; (name is now not
coming from &amp;#8220;Tree Tucker&amp;#8221;, but from &amp;#8220;Three dimensional Tensors&amp;#8221; which
are the defining parameters of the format) format is presented, which is
much simpler than the recursive &lt;span class="caps"&gt;TT&lt;/span&gt; format and the subspace format by
Hackbusch and Kuhn (they do not present any numerical experiments). It
presents a nice and clear way to implement basic operations, like
matrix-by-vector product, multidimensional convolution, norms, and what
is the most important, the recompression procedure is based entirely on
the &lt;span class="caps"&gt;SVD&lt;/span&gt; and &lt;span class="caps"&gt;QR&lt;/span&gt; decompositions. Its implementation takes about 150 lines
of Matlab code compared to thousand of lines for the recursive
&lt;span class="caps"&gt;TT&lt;/span&gt;-format, andÂ&amp;nbsp; the results for the computation of the smallest
eigenvalue of a 19-dimensional operator are&amp;nbsp;presented.&lt;/p&gt;
</summary></entry><entry><title>Breaking the curse of dimensionality</title><link href="/news/breaking-the-curse-of-dimensionality/" rel="alternate"></link><published>2009-01-30T20:29:00+03:00</published><author><name>Admin</name></author><id>tag:,2009-01-30:news/breaking-the-curse-of-dimensionality/</id><summary type="html">&lt;p&gt;In our new publication, &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=16"&gt;&amp;#8220;Breaking the curse of dimensionality, or how
to use &lt;span class="caps"&gt;SVD&lt;/span&gt; in many dimensions&amp;#8221;&lt;/a&gt; we present a simple recursive
decomposition for multidimensional functions, operators, vectors and
matrices. We prove that in the case when the canonical decomposition
exists our new Tree-Tucker decomposition also exists with the same (and
often fewer) number of parameters. However, unlike the canonical
decomposition, the Tree-Tucker format is stable and robustly computable
by exploiting the &lt;span class="caps"&gt;SVD&lt;/span&gt; decomposition (or any rank-revealing
decomposition). We show how to perform a simple operation
(multidimensional convolution) in such format and provide numerical
experiments for the dimensions up to d=200 on a notebook in several&amp;nbsp;minutes.&lt;/p&gt;
</summary></entry><entry><title>How to find a good submatrix</title><link href="/news/how-to-find-a-good-submatrix/" rel="alternate"></link><published>2008-10-17T18:22:00+04:00</published><author><name>Admin</name></author><id>tag:,2008-10-17:news/how-to-find-a-good-submatrix/</id><summary type="html">&lt;p&gt;Check out ourÂ&amp;nbsp; new paper, &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=15"&gt;&amp;#8220;How to find a good submatrix&amp;#8221;&lt;/a&gt; . It
contains the description of an algorithm to find the well-conditioned
submatrix in a given matrix. This algorithm plays a crucial role in our
low-rank approximation methods, both for matrices and tensors. [drain
file 2 url Matlab code is&amp;nbsp;here].&lt;/p&gt;
</summary></entry><entry><title>Working with tensor-structured matrices and vectors</title><link href="/news/working-with-tensor-structured-matrices-and-vectors/" rel="alternate"></link><published>2008-07-01T00:08:00+04:00</published><author><name>Admin</name></author><id>tag:,2008-07-01:news/working-with-tensor-structured-matrices-and-vectors/</id><summary type="html">&lt;p&gt;A new publication on tensor-structured matrices, with a tentative title
&lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=13"&gt;&amp;#8220;Linear algebra for tensor problems&amp;#8221;&lt;/a&gt; is added. It is submitted to the
special issue of &lt;a class="reference external" href="http://www.springer.com/springerwiennewyork/mathematics/journal/607"&gt;Computing&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This paper is aboutÂ&amp;nbsp; structured iterations with matrices of low tensor
rank in three dimensions. We show that in three dimensions we can use
&lt;em&gt;Tucker decomposition&lt;/em&gt; instead of the canonical decomposition without
any substantial increase in the computational cost. To achieve this goal
we have to compute quite complex six-fold sum, but it is shown that they
can be computed with calls to &lt;span class="caps"&gt;BLAS&lt;/span&gt;/&lt;span class="caps"&gt;LAPACK&lt;/span&gt;. Therefore Tucker format is
highly recommended for 3-dimensional problems. With a current &lt;span class="caps"&gt;MATLAB&lt;/span&gt;
code (will be posted here soon)Â&amp;nbsp; it is possible to handle dense
matrices (i.e., approximate inversion) on a grid of size 256^3.Â&amp;nbsp; In a
future research by using additional approximation techniques we will be
able to increase this number to at least&amp;nbsp;1024^3.&lt;/p&gt;
</summary></entry><entry><title>One more paper on polynomials</title><link href="/news/one-more-paper-on-polynomials/" rel="alternate"></link><published>2008-06-18T13:58:00+04:00</published><author><name>Admin</name></author><id>tag:,2008-06-18:news/one-more-paper-on-polynomials/</id><summary type="html">&lt;p&gt;Added a paper &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=12"&gt;&amp;#8220;Improved n-term Karatsuba formulae in &lt;span class="caps"&gt;GF&lt;/span&gt;(2)&amp;#8221;&lt;/a&gt; that
contains improved (and without proof &amp;#8212;- optimal!) formulae for
multiplication of binary polynomials in &lt;span class="caps"&gt;GF&lt;/span&gt;(2). As noted in the end of
this paper, the goal is not purely theoretic, but also practical &amp;#8212;-
these optimal formulae will be used for the superfast implementation of
the Coppersmith algorithm (as in the work by Thome), where the key step
is the multiplication of binary&amp;nbsp;polynomials.&lt;/p&gt;
</summary></entry><entry><title>Some news</title><link href="/news/some-news/" rel="alternate"></link><published>2008-05-26T02:04:00+04:00</published><author><name>Admin</name></author><id>tag:,2008-05-26:news/some-news/</id><summary type="html">&lt;p&gt;A new &lt;a class="reference external" href="http://spring.inm.ras.ru/osel/wp-content/plugins/wp-publications-archive/openfile.php?action=open&amp;amp;file=10"&gt;publication&lt;/a&gt; has been added. To my knowledge, it is the first
paper where nontrivial class of low-tensor rank matrices with inverses
also of a low tensor rank is found. This class is also not very small
and many useful matrices can be reduced to&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;At present, I have several pieces of work to be done: to write down all
results on the optimal multiplication of binary polynomials (generated
code to multiply 128-degree with polynomials with coefficients in &lt;span class="caps"&gt;GF&lt;/span&gt;(2)
optimally), some more &amp;#8220;old&amp;#8221; results need to be written down. What I&amp;#8217;m
interested in really now, is the fast multipole method. After inspecting
several papers by several people (Biros, Ying, Rokhlin and Martinsson,
etc) I&amp;#8217;ve made some conclusions. First, multipole without multipole is
really possible. Second, those authors do a good job, but they do not
want to read the work of others, especially the works by Tyrtyshnikov,
Goreinov and Zamarashkin, the group of Hackbusch. Such reading may
prevent them from reinventing the wheel in some sense. Third, the best
implementation of the fast multipole lies somewhere in between those
several approaches. That is what is interesting to find out &amp;#8212;-
near-to-optimal realization of the fast multipole algorithm. Maybe some
tricks from the tensor approximation will be useful, especially in&amp;nbsp;3D&lt;/p&gt;
</summary></entry><entry><title>Contacts</title><link href="/news/contacts/" rel="alternate"></link><published>2008-04-03T23:01:00+04:00</published><author><name>Admin</name></author><id>tag:,2008-04-03:news/contacts/</id><summary type="html">&lt;p&gt;You can always contact&amp;nbsp;me&amp;nbsp;by&amp;nbsp;email:&lt;/p&gt;
&lt;/p&gt;&lt;p&gt;ivan.oseledets &lt;span class="caps"&gt;DOG&lt;/span&gt;&amp;nbsp;gmail.com.&lt;/p&gt;
</summary></entry><entry><title>Publications</title><link href="/news/publications/" rel="alternate"></link><published>2008-04-03T23:00:00+04:00</published><author><name>Admin</name></author><id>tag:,2008-04-03:news/publications/</id><summary type="html"></summary></entry><entry><title>Started the creation</title><link href="/news/started-the-creation/" rel="alternate"></link><published>2008-04-03T22:04:00+04:00</published><author><name>Admin</name></author><id>tag:,2008-04-03:news/started-the-creation/</id><summary type="html">&lt;p&gt;That is my personal webpage, and I started its creation in April, 2008.
Hope it will be interesting to&amp;nbsp;somebody&lt;/p&gt;
</summary></entry></feed>